# -*- coding: utf-8 -*-
import os
import sys
import gradio as gr
import google.generativeai as genai
from google.generativeai import types # C·∫ßn thi·∫øt cho ThinkingConfig v√† Content
from google.api_core import exceptions as google_exceptions
import traceback # ƒê·ªÉ in l·ªói chi ti·∫øt h∆°n

# ================= C·∫§U H√åNH API KEY XOAY V√íNG =================
# --- THAY TH·∫æ C√ÅC KEY N√ÄY B·∫∞NG KEY GEMINI TH·ª∞C T·∫æ C·ª¶A B·∫†N ---
API_KEYS = [
    "AIzaSyBybfBSDLx39DdnZbHyLbd21tQAdfHtbeE",  # Key 1 (Key c≈© c·ªßa b·∫°n - c√≥ th·ªÉ kh√¥ng h·ª£p l·ªá)
    "AIzaSyCFCj6v8hD49BICKhnHLEpP5o_Wn7hrJgg",                          # Key 2
    "AIzaSyBxCiE0J23G9jRJvAX7Q9CmPP2BTfTUP4o",                          # Key 3
    "AIzaSyDkeIgLhVdtCKkP3O-E6NtddP1DCdsQJO8",                          # Key 4
]

# L·ªçc b·ªè c√°c key placeholder ho·∫∑c tr·ªëng
API_KEYS = [key for key in API_KEYS if key and not key.startswith("YOUR_")]

current_key_index = 0
# Kh√¥ng c·∫ßn bi·∫øn genai_configured n·ªØa v√¨ Client s·∫Ω ƒë∆∞·ª£c t·∫°o m·ªói l·∫ßn g·ªçi

# H√†m xoay v√≤ng API Key
def rotate_api_key():
    global current_key_index
    if not API_KEYS:
        return None # Kh√¥ng c√≥ key n√†o h·ª£p l·ªá
    current_key_index = (current_key_index + 1) % len(API_KEYS)
    print(f"[INFO] Chuy·ªÉn sang s·ª≠ d·ª•ng API Key #{current_key_index + 1}")
    return API_KEYS[current_key_index]

# ================= MODEL V√Ä C·∫§U H√åNH =================
# --- S·ª¨ D·ª§NG MODEL M·ªöI V√Ä THINKING CONFIG ---
MODEL_NAME = "gemini-2.5-pro-exp-03-25"
print(f"[INFO] S·ª≠ d·ª•ng model: {MODEL_NAME}")

# C·∫•u h√¨nh cho generate_content v·ªõi thinking
# thinking_budget=0 c√≥ nghƒ©a l√† n√≥ s·∫Ω hi·ªÉn th·ªã tr·∫°ng th√°i thinking n·∫øu qu√° tr√¨nh x·ª≠ l√Ω l√¢u
generate_content_config = types.GenerateContentConfig(
    thinking_config=types.ThinkingConfig(
        thinking_budget=0, # =0 ƒë·ªÉ b·∫≠t thinking UI khi c·∫ßn
    ),
    response_mime_type="text/plain", # Y√™u c·∫ßu ph·∫£n h·ªìi d·∫°ng text
)

# ================= H√ÄM X·ª¨ L√ù L·ªñI API =================
def format_api_error(e, key_index):
    error_message = str(e)
    error_type = type(e).__name__
    print(f"[ERROR][Key #{key_index + 1}] L·ªói khi g·ªçi API: {error_type} - {error_message}")
    traceback.print_exc() # In stack trace ƒë·ªÉ debug

    # Ph√¢n lo·∫°i l·ªói ƒë·ªÉ quy·∫øt ƒë·ªãnh c√≥ n√™n xoay key hay kh√¥ng
    is_key_related_error = False
    user_friendly_message = f"‚ùå L·ªói v·ªõi Key #{key_index + 1} ({error_type})"

    if isinstance(e, google_exceptions.PermissionDenied):
        if "API key not valid" in error_message or "API_KEY_INVALID" in error_message:
            user_friendly_message = f"‚ùå L·ªói: API Key #{key_index + 1} kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ b·ªã v√¥ hi·ªáu h√≥a (PermissionDenied)."
            is_key_related_error = True
        else: # L·ªói quy·ªÅn truy c·∫≠p model
            user_friendly_message = f"‚ùå L·ªói: T·ª´ ch·ªëi quy·ªÅn truy c·∫≠p (Permission Denied) cho model '{MODEL_NAME}' v·ªõi Key #{key_index + 1}. Key c√≥ th·ªÉ kh√¥ng c√≥ quy·ªÅn s·ª≠ d·ª•ng model n√†y ho·∫∑c ch∆∞a b·∫≠t 'Generative Language API'."
            is_key_related_error = True # Th∆∞·ªùng l√† v·∫•n ƒë·ªÅ key/quy·ªÅn
    elif isinstance(e, google_exceptions.InvalidArgument):
         if "API key not valid" in error_message:
            user_friendly_message = f"‚ùå L·ªói: API Key #{key_index + 1} kh√¥ng h·ª£p l·ªá (InvalidArgument)."
            is_key_related_error = True
         elif "invalid content" in error_message.lower():
             user_friendly_message = f"‚ùå L·ªói: D·ªØ li·ªáu g·ª≠i ƒëi kh√¥ng h·ª£p l·ªá (InvalidArgument). C√≥ th·ªÉ do l·ªãch s·ª≠ chat b·ªã l·ªói."
             # L·ªói n√†y kh√¥ng ph·∫£i do key, kh√¥ng n√™n xoay v√≤ng
         else:
            user_friendly_message = f"‚ùå L·ªói: Tham s·ªë kh√¥ng h·ª£p l·ªá (InvalidArgument) v·ªõi Key #{key_index + 1}: {error_message}"
            # C√≥ th·ªÉ do key, c√≥ th·ªÉ kh√¥ng, t·∫°m coi l√† kh√¥ng ƒë·ªÉ tr√°nh xoay v√≤ng v√¥ √≠ch
    elif isinstance(e, google_exceptions.NotFound):
         user_friendly_message = f"‚ùå L·ªói: Model '{MODEL_NAME}' kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng t·ªìn t·∫°i v·ªõi API key #{key_index + 1}."
         is_key_related_error = True # C√≥ th·ªÉ do key kh√¥ng c√≥ quy·ªÅn truy c·∫≠p model n√†y
    elif isinstance(e, google_exceptions.ResourceExhausted):
         user_friendly_message = f"‚ùå L·ªói: Key #{key_index + 1} ƒë√£ v∆∞·ª£t qu√° H·∫°n ng·∫°ch API (Quota) ho·∫∑c T√†i nguy√™n ƒë√£ c·∫°n ki·ªát (429)."
         is_key_related_error = True
    elif isinstance(e, google_exceptions.DeadlineExceeded):
         user_friendly_message = f"‚ùå L·ªói: Y√™u c·∫ßu v·ªõi Key #{key_index + 1} v∆∞·ª£t qu√° th·ªùi gian ch·ªù (Timeout/Deadline Exceeded/504)."
         # C√≥ th·ªÉ do m·∫°ng ho·∫∑c server qu√° t·∫£i, kh√¥ng ch·∫Øc do key
    elif isinstance(e, (genai.types.BlockedPromptException, genai.types.StopCandidateException)):
         user_friendly_message = f"‚ö†Ô∏è Y√™u c·∫ßu ho·∫∑c ph·∫£n h·ªìi b·ªã ch·∫∑n b·ªüi b·ªô l·ªçc an to√†n."
         # Kh√¥ng ph·∫£i l·ªói key
    else: # C√°c l·ªói kh√°c
         user_friendly_message = f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh v·ªõi Key #{key_index + 1} ({error_type}): {error_message}"
         # M·∫∑c ƒë·ªãnh coi l√† kh√¥ng li√™n quan ƒë·∫øn key ƒë·ªÉ tr√°nh xoay v√≤ng sai

    return user_friendly_message, is_key_related_error

# H√†m ti·ªán √≠ch ƒë·ªÉ th√™m l·ªói v√†o l·ªãch s·ª≠ chat
def append_error_to_history(error_msg, message, chat_history_state):
    if isinstance(chat_history_state, list):
        # Tr√°nh th√™m l·ªói tr√πng l·∫∑p n·∫øu message gi·ªëng h·ªát
        if not chat_history_state or chat_history_state[-1] != [message, error_msg]:
             chat_history_state.append([message, error_msg])
    else:
        chat_history_state = [[message, error_msg]]
    return "", chat_history_state, chat_history_state


# ================= H√ÄM CALLBACK CH√çNH C·ª¶A GRADIO =================
def respond(message, chat_history_state):
    global current_key_index

    if not API_KEYS:
        error_msg = "‚ùå L·ªói c·∫•u h√¨nh: Danh s√°ch API Key tr·ªëng! Vui l√≤ng th√™m key v√†o bi·∫øn `API_KEYS` trong code."
        return append_error_to_history(error_msg, message, chat_history_state)

    if not message or message.strip() == "":
        error_msg = "‚ö†Ô∏è Vui l√≤ng nh·∫≠p n·ªôi dung tin nh·∫Øn."
        # Kh√¥ng th√™m v√†o l·ªãch s·ª≠, ch·ªâ hi·ªán t·∫°m th·ªùi ho·∫∑c kh√¥ng l√†m g√¨ c·∫£
        # ƒê·ªÉ ƒë∆°n gi·∫£n, ta s·∫Ω kh√¥ng g·ª≠i g√¨ n·∫øu message tr·ªëng
        # N·∫øu mu·ªën hi·ªÉn th·ªã c·∫£nh b√°o trong chatbox, b·∫°n c√≥ th·ªÉ d√πng append_error_to_history
        return "", chat_history_state, chat_history_state # Tr·∫£ v·ªÅ tr·∫°ng th√°i hi·ªán t·∫°i


    current_chat_history = list(chat_history_state)

    # X√¢y d·ª±ng c·∫•u tr√∫c 'contents' t·ª´ l·ªãch s·ª≠ chat cho API m·ªõi
    contents = []
    for user_msg, model_msg in current_chat_history:
        if user_msg and isinstance(user_msg, str):
            contents.append(types.Content(role='user', parts=[types.Part.from_text(text=user_msg)]))
        # Ch·ªâ th√™m tin nh·∫Øn c·ªßa model n·∫øu n√≥ kh√¥ng ph·∫£i l√† l·ªói/c·∫£nh b√°o tr∆∞·ªõc ƒë√≥
        if model_msg and isinstance(model_msg, str) and not model_msg.startswith("‚ùå") and not model_msg.startswith("‚ö†Ô∏è"):
            contents.append(types.Content(role='model', parts=[types.Part.from_text(text=model_msg)]))

    # Th√™m tin nh·∫Øn m·ªõi nh·∫•t c·ªßa ng∆∞·ªùi d√πng
    contents.append(types.Content(role='user', parts=[types.Part.from_text(text=message)]))

    print(f"[INFO] L·ªãch s·ª≠ g·ª≠i ƒëi ('contents' length): {len(contents)}")
    print(f"[INFO] Prompt m·ªõi: '{message[:100]}...'")

    # Th·ª≠ v·ªõi c√°c API key, t·ªëi ƒëa s·ªë l∆∞·ª£ng key c√≥
    initial_key_index = current_key_index
    for attempt in range(len(API_KEYS)):
        active_key = API_KEYS[current_key_index]
        print(f"[INFO] ƒêang th·ª≠ v·ªõi API Key #{current_key_index + 1}...")

        try:
            # 1. Kh·ªüi t·∫°o Client v·ªõi key hi·ªán t·∫°i
            client = genai.Client(api_key=active_key)

            # 2. G·ªçi API generate_content_stream
            response_stream = client.models.generate_content_stream(
                model=f"models/{MODEL_NAME}", # API client y√™u c·∫ßu 'models/' prefix
                contents=contents,
                generation_config=generate_content_config, # S·ª≠ d·ª•ng config ƒë√£ ƒë·ªãnh nghƒ©a
                stream=True,
            )

            # 3. X·ª≠ l√Ω stream response
            current_chat_history.append([message, ""]) # Th√™m c·∫∑p m·ªõi v√†o l·ªãch s·ª≠ UI
            full_response_text = ""
            thinking_active = False

            for chunk in response_stream:
                # --- X·ª≠ l√Ω Thinking ---
                if chunk.thinking_state:
                    if not thinking_active:
                        print("[INFO] ZyraX is ThinKing...")
                        thinking_active = True
                        # C·∫≠p nh·∫≠t UI ƒë·ªÉ hi·ªÉn th·ªã tr·∫°ng th√°i thinking (v√≠ d·ª•: th√™m d·∫•u ...)
                        current_chat_history[-1][1] = full_response_text + "..."
                        yield "", current_chat_history, current_chat_history
                    continue # B·ªè qua chunk thinking, ch·ªù chunk text

                # --- X·ª≠ l√Ω Text ---
                chunk_text = getattr(chunk, 'text', '')
                if chunk_text:
                    if thinking_active:
                        # X√≥a d·∫•u "..." khi c√≥ text ƒë·∫ßu ti√™n sau thinking
                        current_chat_history[-1][1] = full_response_text
                        thinking_active = False

                    full_response_text += chunk_text
                    current_chat_history[-1][1] = full_response_text
                    yield "", current_chat_history, current_chat_history # C·∫≠p nh·∫≠t UI li√™n t·ª•c

                # --- X·ª≠ l√Ω Block/Finish Reason ---
                # L∆∞u √Ω: C·∫•u tr√∫c chunk c·ªßa generate_content_stream c√≥ th·ªÉ kh√°c start_chat
                # Ki·ªÉm tra l√Ω do ch·∫∑n ho·∫∑c k·∫øt th√∫c s·ªõm
                block_reason = getattr(getattr(chunk, 'prompt_feedback', None), 'block_reason', None)
                finish_reason = None
                # Trong generate_content_stream, finish_reason th∆∞·ªùng ·ªü cu·ªëi c√πng ho·∫∑c trong candidate
                if hasattr(chunk, 'candidates') and chunk.candidates:
                     finish_reason = getattr(chunk.candidates[0], 'finish_reason', None)

                reason_text = ""
                should_stop = False
                if block_reason and block_reason != 'BLOCK_REASON_UNSPECIFIED':
                    reason_text, should_stop = f"Y√™u c·∫ßu/Ph·∫£n h·ªìi b·ªã ch·∫∑n ({block_reason})", True
                elif finish_reason and finish_reason not in ['STOP', 'FINISH_REASON_UNSPECIFIED']:
                    reason_text, should_stop = f"Ph·∫£n h·ªìi b·ªã d·ª´ng s·ªõm ({finish_reason})", True

                if reason_text:
                    print(f"[WARN] {reason_text}")
                    warning_msg = f"\n‚ö†Ô∏è ({reason_text})"
                    # Th√™m c·∫£nh b√°o v√†o cu·ªëi tin nh·∫Øn hi·ªán t·∫°i
                    if not current_chat_history[-1][1] or current_chat_history[-1][1].isspace():
                         current_chat_history[-1][1] = warning_msg.strip()
                    elif warning_msg not in current_chat_history[-1][1]:
                         current_chat_history[-1][1] += warning_msg
                    yield "", current_chat_history, current_chat_history
                    if should_stop:
                        print("[INFO] D·ª´ng x·ª≠ l√Ω do block/finish reason.")
                        return # K·∫øt th√∫c h√†m respond

            # 4. Th√†nh c√¥ng v·ªõi key n√†y
            print(f"[OK] Ho√†n th√†nh streaming v·ªõi Key #{current_key_index + 1}.")
            # ƒê·∫£m b·∫£o key hi·ªán t·∫°i ƒë∆∞·ª£c gi·ªØ l·∫°i cho l·∫ßn g·ªçi ti·∫øp theo
            return # Tho√°t kh·ªèi h√†m respond sau khi th√†nh c√¥ng

        except Exception as e:
            error_msg, is_key_error = format_api_error(e, current_key_index)

            if is_key_error:
                # N·∫øu l√† l·ªói li√™n quan ƒë·∫øn key, xoay key v√† th·ª≠ l·∫°i ·ªü v√≤ng l·∫∑p ti·∫øp theo
                rotate_api_key()
                # N·∫øu ƒë√£ th·ª≠ h·∫øt t·∫•t c·∫£ c√°c key v√† quay l·∫°i key ban ƒë·∫ßu, d·ª´ng l·∫°i
                if current_key_index == initial_key_index and attempt == len(API_KEYS) - 1:
                    print("[ERROR] ƒê√£ th·ª≠ t·∫•t c·∫£ API Key nh∆∞ng ƒë·ªÅu th·∫•t b·∫°i.")
                    final_error_msg = f"‚ùå ƒê√£ th·ª≠ t·∫•t c·∫£ {len(API_KEYS)} API Key nh∆∞ng kh√¥ng th√†nh c√¥ng. L·ªói cu·ªëi c√πng: {error_msg}"
                    return append_error_to_history(final_error_msg, message, current_chat_history)
                # N·∫øu ch∆∞a h·∫øt, ti·∫øp t·ª•c v√≤ng l·∫∑p ƒë·ªÉ th·ª≠ key ti·∫øp theo
                continue
            else:
                # N·∫øu l·ªói kh√¥ng li√™n quan ƒë·∫øn key (v√≠ d·ª•: n·ªôi dung b·ªã ch·∫∑n, l·ªói server kh√°c...),
                # kh√¥ng c·∫ßn th·ª≠ c√°c key kh√°c cho c√πng m·ªôt y√™u c·∫ßu n√†y.
                print(f"[ERROR] G·∫∑p l·ªói kh√¥ng li√™n quan ƒë·∫øn API key, d·ª´ng th·ª≠ c√°c key kh√°c cho y√™u c·∫ßu n√†y.")
                return append_error_to_history(error_msg, message, current_chat_history)

    # N·∫øu v√≤ng l·∫∑p k·∫øt th√∫c m√† kh√¥ng th√†nh c√¥ng (th∆∞·ªùng l√† do t·∫•t c·∫£ key ƒë·ªÅu l·ªói)
    print("[ERROR] Kh√¥ng th·ªÉ ho√†n th√†nh y√™u c·∫ßu sau khi th·ª≠ t·∫•t c·∫£ c√°c API Key.")
    final_error_msg = f"‚ùå ƒê√£ th·ª≠ t·∫•t c·∫£ {len(API_KEYS)} API Key nh∆∞ng kh√¥ng th√†nh c√¥ng."
    return append_error_to_history(final_error_msg, message, current_chat_history)


# ================= GIAO DI·ªÜN GRADIO (Gi·ªØ nguy√™n t·ª´ phi√™n b·∫£n tr∆∞·ªõc) =================
custom_theme = gr.themes.Soft(
    primary_hue="emerald",
    secondary_hue="gray",
).set(
    button_primary_background_fill="*primary_500",
    button_primary_background_fill_hover="*primary_400",
    chatbot_code_background_color="*primary_50",
)

with gr.Blocks(theme=custom_theme, title="ZyRa X - Gemini Pro (Thinking)") as demo:
    # Header
    with gr.Row():
        gr.HTML("""
            <div style="text-align: center; width: 100%;">
                <h1 style="font-family: 'Segoe UI', sans-serif; color: #2ecc71;">
                    <img src="https://i.ibb.co/3yRk2L2/ai-icon.png"
                         style="height: 40px; vertical-align: middle; margin-right: 10px;">ZyRa X
                </h1>
                <p style="color: #7f8c8d;">Model: Gemini 1.5 Pro (Thinking Enabled) - Multi API Key</p>
            </div>
        """)

    # Chat Interface
    chatbot = gr.Chatbot(
        label="L·ªãch s·ª≠ Chat",
        height=600,
        avatar_images=(
            "https://i.ibb.co/rdZC7LZ/user-avatar.png", # Avatar ng∆∞·ªùi d√πng
            "https://i.ibb.co/3yRk2L2/ai-icon.png"      # Avatar AI
        ),
        bubble_full_width=False,
        render_markdown=True,
        show_label=False,
         latex_delimiters=[
            { "left": "$$", "right": "$$", "display": True },
            { "left": "$", "right": "$", "display": False },
            { "left": "\\[", "right": "\\]", "display": True },
            { "left": "\\(", "right": "\\)", "display": False }
        ]
    )

    # State ƒë·ªÉ l∆∞u l·ªãch s·ª≠ chat
    chat_history_state = gr.State([])
    # State ƒë·ªÉ l∆∞u ch·ªâ s·ªë key hi·ªán t·∫°i (c√≥ th·ªÉ d√πng ƒë·ªÉ hi·ªÉn th·ªã n·∫øu mu·ªën)
    key_index_state = gr.State(current_key_index)

    # Control Panel
    with gr.Row():
        with gr.Column(scale=8):
            msg = gr.Textbox(
                placeholder="Nh·∫≠p c√¢u h·ªèi ho·∫∑c y√™u c·∫ßu c·ªßa b·∫°n ·ªü ƒë√¢y...",
                lines=2,
                max_lines=5,
                label="Tin nh·∫Øn",
                container=False,
                show_label=False,
            )
        with gr.Column(scale=1, min_width=80):
            send_btn = gr.Button("G·ª≠i", variant="primary", size="sm") # L√†m n√∫t nh·ªè h∆°n ch√∫t
        with gr.Column(scale=1, min_width=80):
            clear_btn = gr.Button("üóëÔ∏è X√≥a", variant="secondary", size="sm") # N√∫t x√≥a nh·ªè h∆°n

    # Hi·ªÉn th·ªã tr·∫°ng th√°i Key (T√πy ch·ªçn, c√≥ th·ªÉ b·ªè ƒëi n·∫øu kh√¥ng c·∫ßn)
    with gr.Accordion("‚ìò Tr·∫°ng th√°i API", open=False):
         key_status_display = gr.Markdown(f"S·∫µn s√†ng s·ª≠ d·ª•ng Key #{current_key_index + 1} / {len(API_KEYS) if API_KEYS else 0}", elem_id="key-status")

    # --- K·∫øt n·ªëi s·ª± ki·ªán ---
    # H√†m x·ª≠ l√Ω khi g·ª≠i tin nh·∫Øn (Enter ho·∫∑c n√∫t G·ª≠i)
    def submit_message(message, history, key_idx_state):
        # C·∫≠p nh·∫≠t key_index_state tr∆∞·ªõc khi g·ªçi respond
        # (M·∫∑c d√π respond d√πng global, state n√†y ƒë·ªÉ UI c√≥ th·ªÉ c·∫≠p nh·∫≠t n·∫øu c·∫ßn)
        yield from respond(message, history)
        # C·∫≠p nh·∫≠t hi·ªÉn th·ªã tr·∫°ng th√°i key sau khi respond c√≥ th·ªÉ ƒë√£ xoay key
        new_key_idx = current_key_index # L·∫•y gi√° tr·ªã global m·ªõi nh·∫•t
        key_info = f"ƒêang d√πng Key #{new_key_idx + 1} / {len(API_KEYS) if API_KEYS else 0}"
        yield gr.update(value=key_info) # Tr·∫£ v·ªÅ update cho key_status_display

    # T·∫°o m·ªôt output ·∫©n ƒë·ªÉ nh·∫≠n c·∫≠p nh·∫≠t cho key_status_display
    hidden_output_for_status = gr.Markdown(visible=False)

    # K·∫øt n·ªëi s·ª± ki·ªán submit v√† click
    submit_event = msg.submit(
        submit_message,
        inputs=[msg, chat_history_state, key_index_state],
        outputs=[msg, chatbot, chat_history_state, key_status_display] # Th√™m key_status_display v√†o outputs
    )
    click_event = send_btn.click(
        submit_message,
        inputs=[msg, chat_history_state, key_index_state],
        outputs=[msg, chatbot, chat_history_state, key_status_display] # Th√™m key_status_display v√†o outputs
    )

    # H√†m x√≥a chat
    def clear_chat_func():
        global current_key_index
        # Kh√¥ng reset key index khi x√≥a chat, ƒë·ªÉ n√≥ ti·∫øp t·ª•c t·ª´ key ƒëang d√πng
        key_info = f"ƒêang d√πng Key #{current_key_index + 1} / {len(API_KEYS) if API_KEYS else 0}"
        return "", [], key_info # Tr·∫£ v·ªÅ message tr·ªëng, history tr·ªëng, v√† text tr·∫°ng th√°i key m·ªõi

    clear_btn.click(
        clear_chat_func,
        outputs=[msg, chatbot, chat_history_state, key_status_display], # C·∫≠p nh·∫≠t c·∫£ tr·∫°ng th√°i key
        queue=False # Kh√¥ng c·∫ßn queue cho vi·ªác x√≥a
    )

# ================= CH·∫†Y ·ª®NG D·ª§NG =================
if __name__ == "__main__":
    if not API_KEYS:
        print("\n" + "="*50)
        print("‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y API Key h·ª£p l·ªá n√†o trong danh s√°ch `API_KEYS`.")
        print("   Vui l√≤ng ch·ªânh s·ª≠a file app.py v√† th√™m c√°c API Key c·ªßa b·∫°n.")
        print("="*50 + "\n")
        # sys.exit("Tho√°t do thi·∫øu API Key.") # C√≥ th·ªÉ tho√°t h·∫≥n n·∫øu mu·ªën

    print("ƒêang kh·ªüi ch·∫°y Gradio UI...")
    demo.queue().launch(
        server_name='0.0.0.0',
        server_port=int(os.environ.get('PORT', 7860)),
        share=False, # ƒê·∫∑t l√† True n·∫øu mu·ªën t·∫°o link public t·∫°m th·ªùi
        debug=False, # ƒê·∫∑t l√† True ƒë·ªÉ xem log debug c·ªßa Gradio
        favicon_path="https://i.ibb.co/3yRk2L2/ai-icon.png" # Favicon cho tab tr√¨nh duy·ªát
    )
    print("Gradio UI ƒë√£ kh·ªüi ch·∫°y.")
