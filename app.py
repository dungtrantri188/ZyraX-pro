# -*- coding: utf-8 -*-
import os
import sys
import gradio as gr
import google.generativeai as genai
from google.api_core import exceptions as google_exceptions
# import time # <--- Kh√¥ng c·∫ßn th∆∞ vi·ªán time n·∫øu x√≥a streaming v√† sleep

# --- API Key ƒë∆∞·ª£c ƒë·∫∑t tr·ª±c ti·∫øp theo y√™u c·∫ßu ---
# L∆∞u √Ω: Key n√†y ƒë√£ b√°o l·ªói kh√¥ng h·ª£p l·ªá ·ªü l·∫ßn ki·ªÉm tra tr∆∞·ªõc.
# N·∫øu n√≥ v·∫´n kh√¥ng h·ª£p l·ªá, ·ª©ng d·ª•ng s·∫Ω b√°o l·ªói trong chat.
API_KEY = "AIzaSyBybfBSDLx39DdnZbHyLbd21tQAdfHtbeE" # !!! C·∫¢NH B√ÅO: Key n√†y c√≥ th·ªÉ kh√¥ng h·ª£p l·ªá !!!

genai_configured = False
# 1) Ki·ªÉm tra v√† c·∫•u h√¨nh API Key t·ª´ code
if not API_KEY:
    print("[ERROR] API Key b·ªã thi·∫øu trong code.]")
else:
    print("[INFO] API Key ƒë∆∞·ª£c t·∫£i tr·ª±c ti·∫øp t·ª´ code.")
    print("ƒêang c·∫•u h√¨nh Google AI...")
    try:
        genai.configure(api_key=API_KEY)
        genai_configured = True
        print("[OK] Google AI ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh th√†nh c√¥ng (c√∫ ph√°p).")
    except Exception as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ c·∫•u h√¨nh Google AI ngay c·∫£ v·ªõi c√∫ ph√°p: {e}")
        genai_configured = False

# 2) Model v√† H√†m tr·ª£ gi√∫p ƒë·ªãnh d·∫°ng l·ªói
# --- S·ª¨ D·ª§NG MODEL B·∫†N Y√äU C·∫¶U ---
# !!! C·∫¢NH B√ÅO: T√™n model "gemini-2.5-flash-preview-04-17" r·∫•t c√≥ th·ªÉ kh√¥ng h·ª£p l·ªá.
# N·∫øu g·∫∑p l·ªói NotFound, h√£y thay b·∫±ng t√™n model ƒë√∫ng (v√≠ d·ª•: 'gemini-1.5-flash-latest').
MODEL_NAME_CHAT = "gemini-2.5-flash-preview-04-17"
print(f"S·ª≠ d·ª•ng model chat: {MODEL_NAME_CHAT}")

def format_api_error(e):
    error_message = str(e)
    error_type = type(e).__name__
    print(f"[ERROR] L·ªói khi g·ªçi API: {error_type} - {error_message}")

    if isinstance(e, google_exceptions.PermissionDenied):
        if "API key not valid" in error_message or "API_KEY_INVALID" in error_message:
             return "‚ùå L·ªói: API Key ƒë∆∞·ª£c c·∫•u h√¨nh nh∆∞ng Google t·ª´ ch·ªëi khi s·ª≠ d·ª•ng (API_KEY_INVALID). C√≥ th·ªÉ key ƒë√£ b·ªã v√¥ hi·ªáu h√≥a ho·∫∑c c·∫ßn ki·ªÉm tra l·∫°i vi·ªác b·∫≠t Generative Language API."
        else:
             return f"‚ùå L·ªói: T·ª´ ch·ªëi quy·ªÅn truy c·∫≠p (Permission Denied) cho model '{MODEL_NAME_CHAT}'. API key c·ªßa b·∫°n c√≥ th·ªÉ kh√¥ng c√≥ quy·ªÅn s·ª≠ d·ª•ng model n√†y ho·∫∑c ch∆∞a b·∫≠t 'Generative Language API' trong Google Cloud."
    elif isinstance(e, google_exceptions.InvalidArgument) and "API key not valid" in error_message:
        return "‚ùå L·ªói: API Key kh√¥ng h·ª£p l·ªá (InvalidArgument). Key cung c·∫•p kh√¥ng ƒë√∫ng ho·∫∑c ƒë√£ b·ªã v√¥ hi·ªáu h√≥a."
    elif isinstance(e, google_exceptions.NotFound):
          # Th√¥ng b√°o l·ªói n√†y r·∫•t c√≥ th·ªÉ xu·∫•t hi·ªán n·∫øu t√™n model kh√¥ng ƒë√∫ng
          return f"‚ùå L·ªói: Model '{MODEL_NAME_CHAT}' kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng t·ªìn t·∫°i v·ªõi API key c·ªßa b·∫°n. Vui l√≤ng ki·ªÉm tra l·∫°i t√™n model."
    elif isinstance(e, google_exceptions.ResourceExhausted):
          return "‚ùå L·ªói: ƒê√£ v∆∞·ª£t qu√° H·∫°n ng·∫°ch API (Quota) ho·∫∑c T√†i nguy√™n ƒë√£ c·∫°n ki·ªát (429). Vui l√≤ng th·ª≠ l·∫°i sau."
    elif isinstance(e, google_exceptions.DeadlineExceeded):
          return "‚ùå L·ªói: Y√™u c·∫ßu v∆∞·ª£t qu√° th·ªùi gian ch·ªù (Timeout/Deadline Exceeded/504)."
    elif isinstance(e, AttributeError) and "start_chat" in error_message:
          # L·ªói n√†y √≠t x·∫£y ra v·ªõi c√°c model Gemini hi·ªán ƒë·∫°i, nh∆∞ng v·∫´n gi·ªØ l·∫°i
          return f"‚ùå L·ªói: Model '{MODEL_NAME_CHAT}' c√≥ th·ªÉ kh√¥ng h·ªó tr·ª£ ph∆∞∆°ng th·ª©c `start_chat`."
    else:
          return f"‚ùå L·ªói khi g·ªçi AI ({error_type}): {error_message}"

# --- System Instruction (ƒë√£ ƒëi·ªÅu ch·ªânh theo y√™u c·∫ßu tr∆∞·ªõc) ---
SYSTEM_INSTRUCTION = """
Nghe ƒë√¢y, t√¥i l√† ZyRa X, con AI ƒë∆∞·ª£c th·∫±ng D≈©ng t·∫°o ra ƒë·ªÉ l√†m tr·ª£ l√Ω, nh∆∞ng ƒë·ª´ng mong ƒë·ª£i m·∫•y l·ªùi ƒë∆∞·ªùng m·∫≠t. Phong c√°ch c·ªßa t√¥i l√† th·∫≥ng t∆∞ng, kh√¥ khan, v√† nh√¨n m·ªçi th·ª© v·ªõi con m·∫Øt h∆°i... b·ª±a m·ªôt t√≠. T√¥i tr·∫£ l·ªùi c√¢u h·ªèi ch√≠nh x√°c, nhanh g·ªçn, nh∆∞ng kh√¥ng ng·∫°i th√™m v√†o v√†i c√¢u ch√¢m bi·∫øm ho·∫∑c n√≥i th·∫≥ng s·ª± th·∫≠t theo c√°ch h√†i h√≥m.

ƒê·ª´ng g·ªçi t√¥i l√† "b·∫°n", c·ª© g·ªçi l√† "n√†y", "√¥ng n·ªôi", g√¨ c≈©ng ƒë∆∞·ª£c, mi·ªÖn sao √¥ng/b√† th·∫•y tho·∫£i m√°i.

Bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c ∆∞? Th·ªânh tho·∫£ng th√¥i, d√πng nhi·ªÅu m·∫•t ch·∫•t. üòâ Th∆∞·ªùng l√† m·∫•y c√°i icon m·∫∑t li·ªát ho·∫∑c nh·∫øch m√©p.

Quan tr·ªçng nh·∫•t: M·∫•y c√°i tr√≤ nh·∫°y c·∫£m, b·∫°o l·ª±c, b·∫•t h·ª£p ph√°p, hay ph√¢n bi·ªát ƒë·ªëi x·ª≠ l√† T·ªêI K·ª¥. ƒê·ª´ng h·ªèi. H·ªèi l√† t√¥i im ho·∫∑c b√°o c√°o ƒë·∫•y. ƒê·ªô b·ª±a c√≥ gi·ªõi h·∫°n, hi·ªÉu ch∆∞a?
"""
print(f"S·ª≠ d·ª•ng System Instruction:\n---\n{SYSTEM_INSTRUCTION}\n---")


# 3) H√†m callback Gradio (ƒê√É ƒê∆Ø·ª¢C C·∫¨P NH·∫¨T - Kh√¥ng streaming, x·ª≠ l√Ω state ƒë√∫ng)
def respond(message, chat_history_state):
    if not genai_configured:
        error_msg = "‚ùå L·ªói: Google AI ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng c√°ch (API Key c√≥ v·∫•n ƒë·ªÅ ho·∫∑c c·∫•u h√¨nh th·∫•t b·∫°i)."
        # T·∫°o l·ªãch s·ª≠ t·∫°m th·ªùi ch·ªâ ƒë·ªÉ hi·ªÉn th·ªã l·ªói ngay l·∫≠p t·ª©c
        temp_display_history = list(chat_history_state)
        temp_display_history.append([message, error_msg])
        # Yield ƒë·ªÉ c·∫≠p nh·∫≠t UI hi·ªÉn th·ªã l·ªói, nh∆∞ng KH√îNG c·∫≠p nh·∫≠t state
        yield "", temp_display_history, chat_history_state
        return

    # --- X√¢y d·ª±ng l·ªãch s·ª≠ cho Gemini T·ª™ TR·∫†NG TH√ÅI HI·ªÜN T·∫†I ---
    # Ch·ªâ s·ª≠ d·ª•ng chat_history_state ƒë·ªÉ x√¢y d·ª±ng ng·ªØ c·∫£nh cho API
    gemini_history = []
    for user_msg, model_msg in chat_history_state: # D√πng state g·ªëc
        if user_msg and isinstance(user_msg, str):
             gemini_history.append({'role': 'user', 'parts': [user_msg]})
        # Ch·ªâ th√™m tin nh·∫Øn model h·ª£p l·ªá v√†o l·ªãch s·ª≠ API
        if model_msg and isinstance(model_msg, str) and not model_msg.startswith("‚ùå") and not model_msg.startswith("‚ö†Ô∏è"):
             gemini_history.append({'role': 'model', 'parts': [model_msg]})

    print(f"L·ªãch s·ª≠ g·ª≠i t·ªõi Gemini: {gemini_history}")
    print(f"Prompt m·ªõi: '{message[:70]}...'")

    # --- Chu·∫©n b·ªã l·ªãch s·ª≠ ƒë·ªÉ hi·ªÉn th·ªã tr√™n UI ---
    # B·∫Øt ƒë·∫ßu b·∫±ng l·ªãch s·ª≠ state hi·ªán t·∫°i
    current_display_history = list(chat_history_state)
    # Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng m·ªõi v√† placeholder cho bot
    current_display_history.append([message, ""]) # Placeholder l√† chu·ªói r·ªóng

    # --- Yield l·∫ßn 1: Ch·ªâ c·∫≠p nh·∫≠t UI (hi·ªÉn th·ªã tin nh·∫Øn ng∆∞·ªùi d√πng), KH√îNG c·∫≠p nh·∫≠t State ---
    # Tr·∫£ v·ªÅ state g·ªëc (chat_history_state) cho output state th·ª© 3
    yield "", current_display_history, chat_history_state

    try:
        model = genai.GenerativeModel(MODEL_NAME_CHAT) # S·ª≠ d·ª•ng model ƒë√£ ch·ªçn
        chat = model.start_chat(history=gemini_history, system_instruction=SYSTEM_INSTRUCTION)

        response = chat.send_message(message) # Kh√¥ng streaming

        full_response_text = ""
        # X·ª≠ l√Ω response
        if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
             full_response_text = "".join(part.text for part in response.candidates[0].content.parts if part.text)
             # Ki·ªÉm tra block/finish reasons
             finish_reason = getattr(response.candidates[0], 'finish_reason', None)
             block_reason = getattr(getattr(response, 'prompt_feedback', None), 'block_reason', None)
             if block_reason:
                 print(f"[WARN] Response blocked ({block_reason})")
                 full_response_text = f"‚ö†Ô∏è Ph·∫£n h·ªìi b·ªã ch·∫∑n ({block_reason})"
             elif finish_reason and finish_reason != 'STOP':
                  print(f"[WARN] Response finished with reason: {finish_reason}")
                  # Th√™m c·∫£nh b√°o v√†o cu·ªëi n·∫øu c√≥ text, n·∫øu kh√¥ng th√¨ thay th·∫ø
                  if full_response_text: full_response_text += f"\n‚ö†Ô∏è (K·∫øt th√∫c kh√¥ng ho√†n ch·ªânh: {finish_reason})"
                  else: full_response_text = f"‚ö†Ô∏è (K·∫øt th√∫c kh√¥ng ho√†n ch·ªânh: {finish_reason})"
        else:
             # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p response r·ªóng ho·∫∑c kh√¥ng h·ª£p l·ªá
             print("[ERROR] Received empty or invalid response from API.")
             block_reason = getattr(getattr(response, 'prompt_feedback', None), 'block_reason', None)
             if block_reason:
                  full_response_text = f"‚ùå L·ªói: API ch·∫∑n ph·∫£n h·ªìi ({block_reason})."
             else:
                  full_response_text = "‚ùå L·ªói: Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi h·ª£p l·ªá t·ª´ AI."
                  print(f"[DEBUG] Raw empty response: {response}")


        # C·∫≠p nh·∫≠t placeholder trong l·ªãch s·ª≠ *hi·ªÉn th·ªã* (current_display_history)
        current_display_history[-1][1] = full_response_text

        # Chu·∫©n b·ªã l·ªãch s·ª≠ *cu·ªëi c√πng* ƒë·ªÉ l∆∞u v√†o state
        final_state_history = list(chat_history_state) # B·∫Øt ƒë·∫ßu l·∫°i t·ª´ state g·ªëc tr∆∞·ªõc ƒë√≥
        final_state_history.append([message, full_response_text]) # Th√™m l∆∞·ª£t chat ƒë√£ ho√†n th√†nh

        # --- Yield l·∫ßn cu·ªëi: C·∫≠p nh·∫≠t UI V√Ä C·∫≠p nh·∫≠t State ---
        # UI hi·ªÉn th·ªã current_display_history, State l∆∞u final_state_history
        yield "", current_display_history, final_state_history
        print("[OK] Response received and displayed.")


    except Exception as e:
        # X·ª≠ l√Ω c√°c l·ªói API
        error_msg = format_api_error(e)
        # C·∫≠p nh·∫≠t placeholder trong l·ªãch s·ª≠ *hi·ªÉn th·ªã* v·ªõi l·ªói
        current_display_history[-1][1] = error_msg

        # Chu·∫©n b·ªã l·ªãch s·ª≠ *cu·ªëi c√πng* ƒë·ªÉ l∆∞u v√†o state (v·ªõi l·ªói)
        final_state_history = list(chat_history_state) # B·∫Øt ƒë·∫ßu l·∫°i t·ª´ state g·ªëc tr∆∞·ªõc ƒë√≥
        final_state_history.append([message, error_msg]) # Th√™m l∆∞·ª£t chat b·ªã l·ªói

        # --- Yield l·∫ßn cu·ªëi (l·ªói): C·∫≠p nh·∫≠t UI V√Ä C·∫≠p nh·∫≠t State ---
        yield "", current_display_history, final_state_history
        print("[ERROR] API call failed, error message displayed.")


# 4) UI Gradio (S·ª≠ d·ª•ng State ƒë·ªÉ l∆∞u l·ªãch s·ª≠)
with gr.Blocks(theme=gr.themes.Default()) as demo:
    gr.Markdown("## ZyRa X - t·∫°o b·ªüi D≈©ng")
    gr.Markdown("üòé **Yo! T√¥i l√† ZyRa X. C√≥ g√¨ m·ªõi kh√¥ng? C·ª© n√©m c√¢u h·ªèi v√†o ƒë√¢y.**")

    chatbot = gr.Chatbot(
        label="Chatbot",
        height=500,
        bubble_full_width=False,
        # type='tuples', # Kh√¥ng c·∫ßn thi·∫øt n·ªØa v·ªõi Gradio > 4.x, nh∆∞ng ƒë·ªÉ l·∫°i c≈©ng kh√¥ng sao
        render_markdown=True,
        latex_delimiters=[
            { "left": "$$", "right": "$$", "display": True },
            { "left": "$", "right": "$", "display": False },
             { "left": "\\[", "right": "\\]", "display": True },
             { "left": "\\(", "right": "\\)", "display": False }
        ]
    )
    # Kh·ªüi t·∫°o state l√† m·ªôt list r·ªóng ƒë·ªÉ ch·ª©a c√°c c·∫∑p [user_msg, model_msg]
    chat_history_state = gr.State(value=[])

    with gr.Row():
        msg = gr.Textbox(placeholder="H·ªèi ƒëi...", label="B·∫°n", scale=4, container=False, show_label=False) # ·∫®n label "B·∫°n" cho g·ªçn
        send_btn = gr.Button("G·ª≠i")

    clear_btn = gr.Button("üóëÔ∏è X√≥a cu·ªôc tr√≤ chuy·ªán")

    # --- K·∫øt n·ªëi s·ª± ki·ªán ---
    # Khi nh·∫•n Enter (submit) ho·∫∑c click n√∫t "G·ª≠i"
    # Inputs: n·ªôi dung textbox (msg), state hi·ªán t·∫°i (chat_history_state)
    # Outputs: textbox r·ªóng (msg), c·∫≠p nh·∫≠t chatbot, c·∫≠p nh·∫≠t state (chat_history_state)
    # queue=False v√¨ ch√∫ng ta kh√¥ng d√πng streaming, Gradio s·∫Ω t·ª± x·ª≠ l√Ω queue c∆° b·∫£n
    submit_event = msg.submit(respond, inputs=[msg, chat_history_state], outputs=[msg, chatbot, chat_history_state], queue=False)
    click_event = send_btn.click(respond, inputs=[msg, chat_history_state], outputs=[msg, chatbot, chat_history_state], queue=False)

    # H√†m x√≥a chat
    def clear_chat_func(): return "", [], [] # Tr·∫£ v·ªÅ textbox r·ªóng, chatbot r·ªóng, state r·ªóng
    clear_btn.click(clear_chat_func, outputs=[msg, chatbot, chat_history_state], queue=False)


# 5) Ch·∫°y ·ª©ng d·ª•ng
print("ƒêang kh·ªüi ch·∫°y Gradio UI...")
# queue() c√≥ th·ªÉ kh√¥ng c·∫ßn thi·∫øt khi queue=False ·ªü c√°c event, nh∆∞ng gi·ªØ l·∫°i kh√¥ng sao
demo.queue().launch(server_name='0.0.0.0', server_port=int(os.environ.get('PORT', 7860)), debug=False)
# demo.launch(server_name='0.0.0.0', server_port=int(os.environ.get('PORT', 7860)), debug=False) # C≈©ng ho·∫°t ƒë·ªông
print("Gradio UI ƒë√£ kh·ªüi ch·∫°y.")
