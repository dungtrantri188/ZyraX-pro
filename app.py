# -*- coding: utf-8 -*-
import os
import sys
import gradio as gr
import google.generativeai as genai
from google.generativeai import types # C·∫ßn thi·∫øt cho ThinkingConfig v√† Content
from google.api_core import exceptions as google_exceptions
import traceback # ƒê·ªÉ in l·ªói chi ti·∫øt h∆°n

# ================= C·∫§U H√åNH API KEY XOAY V√íNG =================
# --- THAY TH·∫æ C√ÅC KEY N√ÄY B·∫∞NG KEY GEMINI TH·ª∞C T·∫æ C·ª¶A B·∫†N ---
API_KEYS = [
    "AIzaSyBybfBSDLx39DdnZbHyLbd21tQAdfHtbeE",  # Key 1 (Key c≈© c·ªßa b·∫°n - c√≥ th·ªÉ kh√¥ng h·ª£p l·ªá)
    "AIzaSyCFCj6v8hD49BICKhnHLEpP5o_Wn7hrJgg",                          # Key 2
    "AIzaSyBxCiE0J23G9jRJvAX7Q9CmPP2BTfTUP4o",                          # Key 3
    "AIzaSyDkeIgLhVdtCKkP3O-E6NtddP1DCdsQJO8",                          # Key 4
    # Th√™m c√°c key kh√°c n·∫øu c·∫ßn
]

# L·ªçc b·ªè c√°c key placeholder ho·∫∑c tr·ªëng (n·∫øu c√≥)
API_KEYS = [key for key in API_KEYS if key and not key.startswith("YOUR_")]

current_key_index = 0
# Kh√¥ng c·∫ßn bi·∫øn genai_configured n·ªØa v√¨ Client s·∫Ω ƒë∆∞·ª£c t·∫°o m·ªói l·∫ßn g·ªçi

# H√†m xoay v√≤ng API Key
def rotate_api_key():
    global current_key_index
    if not API_KEYS:
        return None # Kh√¥ng c√≥ key n√†o h·ª£p l·ªá
    current_key_index = (current_key_index + 1) % len(API_KEYS)
    print(f"[INFO] Chuy·ªÉn sang s·ª≠ d·ª•ng API Key #{current_key_index + 1}")
    return API_KEYS[current_key_index]

# ================= MODEL V√Ä C·∫§U H√åNH =================
# --- S·ª¨ D·ª§NG MODEL M·ªöI V√Ä THINKING CONFIG ---
MODEL_NAME = "gemini-2.5-pro-exp-03-25" # Gi·ªØ nguy√™n model theo y√™u c·∫ßu c·ªßa b·∫°n
print(f"[INFO] S·ª≠ d·ª•ng model: {MODEL_NAME}")

# --- S·ª¨A L·ªñI T·∫†I ƒê√ÇY ---
# C·∫•u h√¨nh cho generate_content v·ªõi thinking
# thinking_budget=0 c√≥ nghƒ©a l√† n√≥ s·∫Ω hi·ªÉn th·ªã tr·∫°ng th√°i thinking n·∫øu qu√° tr√¨nh x·ª≠ l√Ω l√¢u
generation_config = types.GenerationConfig( # <<< S·ª¨A 1: ƒê·ªïi t√™n l·ªõp th√†nh GenerationConfig
    thinking_config=types.ThinkingConfig(
        thinking_budget=0, # =0 ƒë·ªÉ b·∫≠t thinking UI khi c·∫ßn
    ),
    response_mime_type="text/plain", # Y√™u c·∫ßu ph·∫£n h·ªìi d·∫°ng text
)
# --- K·∫æT TH√öC S·ª¨A L·ªñI ---

# ================= H√ÄM X·ª¨ L√ù L·ªñI API =================
def format_api_error(e, key_index):
    error_message = str(e)
    error_type = type(e).__name__
    print(f"[ERROR][Key #{key_index + 1}] L·ªói khi g·ªçi API: {error_type} - {error_message}")
    traceback.print_exc() # In stack trace ƒë·ªÉ debug

    # Ph√¢n lo·∫°i l·ªói ƒë·ªÉ quy·∫øt ƒë·ªãnh c√≥ n√™n xoay key hay kh√¥ng
    is_key_related_error = False
    user_friendly_message = f"‚ùå L·ªói v·ªõi Key #{key_index + 1} ({error_type})"

    if isinstance(e, google_exceptions.PermissionDenied):
        if "API key not valid" in error_message or "API_KEY_INVALID" in error_message:
            user_friendly_message = f"‚ùå L·ªói: API Key #{key_index + 1} kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ b·ªã v√¥ hi·ªáu h√≥a (PermissionDenied)."
            is_key_related_error = True
        else: # L·ªói quy·ªÅn truy c·∫≠p model
            user_friendly_message = f"‚ùå L·ªói: T·ª´ ch·ªëi quy·ªÅn truy c·∫≠p (Permission Denied) cho model '{MODEL_NAME}' v·ªõi Key #{key_index + 1}. Key c√≥ th·ªÉ kh√¥ng c√≥ quy·ªÅn s·ª≠ d·ª•ng model n√†y ho·∫∑c ch∆∞a b·∫≠t 'Generative Language API'."
            is_key_related_error = True # Th∆∞·ªùng l√† v·∫•n ƒë·ªÅ key/quy·ªÅn
    elif isinstance(e, google_exceptions.InvalidArgument):
         if "API key not valid" in error_message:
            user_friendly_message = f"‚ùå L·ªói: API Key #{key_index + 1} kh√¥ng h·ª£p l·ªá (InvalidArgument)."
            is_key_related_error = True
         elif "invalid content" in error_message.lower():
             user_friendly_message = f"‚ùå L·ªói: D·ªØ li·ªáu g·ª≠i ƒëi kh√¥ng h·ª£p l·ªá (InvalidArgument). C√≥ th·ªÉ do l·ªãch s·ª≠ chat b·ªã l·ªói."
             # L·ªói n√†y kh√¥ng ph·∫£i do key, kh√¥ng n√™n xoay v√≤ng
         else:
            user_friendly_message = f"‚ùå L·ªói: Tham s·ªë kh√¥ng h·ª£p l·ªá (InvalidArgument) v·ªõi Key #{key_index + 1}: {error_message}"
            # C√≥ th·ªÉ do key, c√≥ th·ªÉ kh√¥ng, t·∫°m coi l√† kh√¥ng ƒë·ªÉ tr√°nh xoay v√≤ng v√¥ √≠ch
    elif isinstance(e, google_exceptions.NotFound):
         user_friendly_message = f"‚ùå L·ªói: Model '{MODEL_NAME}' kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng t·ªìn t·∫°i v·ªõi API key #{key_index + 1}."
         is_key_related_error = True # C√≥ th·ªÉ do key kh√¥ng c√≥ quy·ªÅn truy c·∫≠p model n√†y
    elif isinstance(e, google_exceptions.ResourceExhausted):
         user_friendly_message = f"‚ùå L·ªói: Key #{key_index + 1} ƒë√£ v∆∞·ª£t qu√° H·∫°n ng·∫°ch API (Quota) ho·∫∑c T√†i nguy√™n ƒë√£ c·∫°n ki·ªát (429)."
         is_key_related_error = True
    elif isinstance(e, google_exceptions.DeadlineExceeded):
         user_friendly_message = f"‚ùå L·ªói: Y√™u c·∫ßu v·ªõi Key #{key_index + 1} v∆∞·ª£t qu√° th·ªùi gian ch·ªù (Timeout/Deadline Exceeded/504)."
         # C√≥ th·ªÉ do m·∫°ng ho·∫∑c server qu√° t·∫£i, kh√¥ng ch·∫Øc do key
    elif isinstance(e, (genai.types.BlockedPromptException, genai.types.StopCandidateException)):
         user_friendly_message = f"‚ö†Ô∏è Y√™u c·∫ßu ho·∫∑c ph·∫£n h·ªìi b·ªã ch·∫∑n b·ªüi b·ªô l·ªçc an to√†n."
         # Kh√¥ng ph·∫£i l·ªói key
    else: # C√°c l·ªói kh√°c
         user_friendly_message = f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh v·ªõi Key #{key_index + 1} ({error_type}): {error_message}"
         # M·∫∑c ƒë·ªãnh coi l√† kh√¥ng li√™n quan ƒë·∫øn key ƒë·ªÉ tr√°nh xoay v√≤ng sai

    return user_friendly_message, is_key_related_error

# H√†m ti·ªán √≠ch ƒë·ªÉ th√™m l·ªói v√†o l·ªãch s·ª≠ chat
def append_error_to_history(error_msg, message, chat_history_state):
    if isinstance(chat_history_state, list):
        # Tr√°nh th√™m l·ªói tr√πng l·∫∑p n·∫øu message gi·ªëng h·ªát
        if not chat_history_state or chat_history_state[-1] != [message, error_msg]:
             chat_history_state.append([message, error_msg])
    else:
        chat_history_state = [[message, error_msg]]
    return "", chat_history_state, chat_history_state


# ================= H√ÄM CALLBACK CH√çNH C·ª¶A GRADIO =================
def respond(message, chat_history_state):
    global current_key_index

    if not API_KEYS:
        error_msg = "‚ùå L·ªói c·∫•u h√¨nh: Danh s√°ch API Key tr·ªëng! Vui l√≤ng th√™m key v√†o bi·∫øn `API_KEYS` trong code."
        return append_error_to_history(error_msg, message, chat_history_state)

    if not message or message.strip() == "":
        error_msg = "‚ö†Ô∏è Vui l√≤ng nh·∫≠p n·ªôi dung tin nh·∫Øn."
        return "", chat_history_state, chat_history_state # Tr·∫£ v·ªÅ tr·∫°ng th√°i hi·ªán t·∫°i


    current_chat_history = list(chat_history_state)

    # X√¢y d·ª±ng c·∫•u tr√∫c 'contents' t·ª´ l·ªãch s·ª≠ chat cho API m·ªõi
    contents = []
    for user_msg, model_msg in current_chat_history:
        if user_msg and isinstance(user_msg, str):
            contents.append(types.Content(role='user', parts=[types.Part.from_text(text=user_msg)]))
        if model_msg and isinstance(model_msg, str) and not model_msg.startswith("‚ùå") and not model_msg.startswith("‚ö†Ô∏è"):
            contents.append(types.Content(role='model', parts=[types.Part.from_text(text=model_msg)]))

    contents.append(types.Content(role='user', parts=[types.Part.from_text(text=message)]))

    print(f"[INFO] L·ªãch s·ª≠ g·ª≠i ƒëi ('contents' length): {len(contents)}")
    print(f"[INFO] Prompt m·ªõi: '{message[:100]}...'")

    initial_key_index = current_key_index
    for attempt in range(len(API_KEYS)):
        active_key = API_KEYS[current_key_index]
        print(f"[INFO] ƒêang th·ª≠ v·ªõi API Key #{current_key_index + 1}...")

        try:
            client = genai.Client(api_key=active_key)

            # --- S·ª¨A L·ªñI T·∫†I ƒê√ÇY ---
            response_stream = client.models.generate_content_stream(
                model=f"models/{MODEL_NAME}",
                contents=contents,
                generation_config=generation_config, # <<< S·ª¨A 2: ƒê·ªïi t√™n bi·∫øn/tham s·ªë th√†nh generation_config
                stream=True,
            )
            # --- K·∫æT TH√öC S·ª¨A L·ªñI ---

            current_chat_history.append([message, ""])
            full_response_text = ""
            thinking_active = False

            for chunk in response_stream:
                if chunk.thinking_state:
                    if not thinking_active:
                        print("[INFO] ZyraX is ThinKing...") # Gi·ªØ nguy√™n log c·ªßa b·∫°n
                        thinking_active = True
                        current_chat_history[-1][1] = full_response_text + "..."
                        yield "", current_chat_history, current_chat_history
                    continue

                chunk_text = getattr(chunk, 'text', '')
                if chunk_text:
                    if thinking_active:
                        current_chat_history[-1][1] = full_response_text
                        thinking_active = False
                    full_response_text += chunk_text
                    current_chat_history[-1][1] = full_response_text
                    yield "", current_chat_history, current_chat_history

                block_reason = getattr(getattr(chunk, 'prompt_feedback', None), 'block_reason', None)
                finish_reason = None
                if hasattr(chunk, 'candidates') and chunk.candidates:
                     finish_reason = getattr(chunk.candidates[0], 'finish_reason', None)

                reason_text = ""
                should_stop = False
                if block_reason and block_reason != 'BLOCK_REASON_UNSPECIFIED':
                    reason_text, should_stop = f"Y√™u c·∫ßu/Ph·∫£n h·ªìi b·ªã ch·∫∑n ({block_reason})", True
                elif finish_reason and finish_reason not in ['STOP', 'FINISH_REASON_UNSPECIFIED']:
                    reason_text, should_stop = f"Ph·∫£n h·ªìi b·ªã d·ª´ng s·ªõm ({finish_reason})", True

                if reason_text:
                    print(f"[WARN] {reason_text}")
                    warning_msg = f"\n‚ö†Ô∏è ({reason_text})"
                    if not current_chat_history[-1][1] or current_chat_history[-1][1].isspace():
                         current_chat_history[-1][1] = warning_msg.strip()
                    elif warning_msg not in current_chat_history[-1][1]:
                         current_chat_history[-1][1] += warning_msg
                    yield "", current_chat_history, current_chat_history
                    if should_stop:
                        print("[INFO] D·ª´ng x·ª≠ l√Ω do block/finish reason.")
                        return

            print(f"[OK] Ho√†n th√†nh streaming v·ªõi Key #{current_key_index + 1}.")
            return

        except Exception as e:
            error_msg, is_key_error = format_api_error(e, current_key_index)
            if is_key_error:
                rotate_api_key()
                if current_key_index == initial_key_index and attempt == len(API_KEYS) - 1:
                    print("[ERROR] ƒê√£ th·ª≠ t·∫•t c·∫£ API Key nh∆∞ng ƒë·ªÅu th·∫•t b·∫°i.")
                    final_error_msg = f"‚ùå ƒê√£ th·ª≠ t·∫•t c·∫£ {len(API_KEYS)} API Key nh∆∞ng kh√¥ng th√†nh c√¥ng. L·ªói cu·ªëi c√πng: {error_msg}"
                    return append_error_to_history(final_error_msg, message, current_chat_history)
                continue
            else:
                print(f"[ERROR] G·∫∑p l·ªói kh√¥ng li√™n quan ƒë·∫øn API key, d·ª´ng th·ª≠ c√°c key kh√°c cho y√™u c·∫ßu n√†y.")
                return append_error_to_history(error_msg, message, current_chat_history)

    print("[ERROR] Kh√¥ng th·ªÉ ho√†n th√†nh y√™u c·∫ßu sau khi th·ª≠ t·∫•t c·∫£ c√°c API Key.")
    final_error_msg = f"‚ùå ƒê√£ th·ª≠ t·∫•t c·∫£ {len(API_KEYS)} API Key nh∆∞ng kh√¥ng th√†nh c√¥ng."
    return append_error_to_history(final_error_msg, message, current_chat_history)


# ================= GIAO DI·ªÜN GRADIO (Gi·ªØ nguy√™n) =================
custom_theme = gr.themes.Soft(
    primary_hue="emerald",
    secondary_hue="gray",
).set(
    button_primary_background_fill="*primary_500",
    button_primary_background_fill_hover="*primary_400",
    chatbot_code_background_color="*primary_50",
)

with gr.Blocks(theme=custom_theme, title="ZyRa X - Gemini Pro (Thinking)") as demo:
    # Header
    with gr.Row():
        gr.HTML("""
            <div style="text-align: center; width: 100%;">
                <h1 style="font-family: 'Segoe UI', sans-serif; color: #2ecc71;">
                    <img src="https://i.ibb.co/3yRk2L2/ai-icon.png"
                         style="height: 40px; vertical-align: middle; margin-right: 10px;">ZyRa X
                </h1>
                <!-- C·∫≠p nh·∫≠t ti√™u ƒë·ªÅ ƒë·ªÉ ph·∫£n √°nh ƒë√∫ng model b·∫°n d√πng -->
                <p style="color: #7f8c8d;">Model: Gemini 2.5 Pro Exp (Thinking Enabled) - Multi API Key</p>
            </div>
        """)

    # Chat Interface
    chatbot = gr.Chatbot(
        label="L·ªãch s·ª≠ Chat",
        height=600,
        avatar_images=(
            "https://i.ibb.co/rdZC7LZ/user-avatar.png", # Avatar ng∆∞·ªùi d√πng
            "https://i.ibb.co/3yRk2L2/ai-icon.png"      # Avatar AI
        ),
        bubble_full_width=False,
        render_markdown=True,
        show_label=False,
         latex_delimiters=[
            { "left": "$$", "right": "$$", "display": True },
            { "left": "$", "right": "$", "display": False },
            { "left": "\\[", "right": "\\]", "display": True },
            { "left": "\\(", "right": "\\)", "display": False }
        ]
    )

    # State ƒë·ªÉ l∆∞u l·ªãch s·ª≠ chat
    chat_history_state = gr.State([])
    # State ƒë·ªÉ l∆∞u ch·ªâ s·ªë key hi·ªán t·∫°i (c√≥ th·ªÉ d√πng ƒë·ªÉ hi·ªÉn th·ªã n·∫øu mu·ªën)
    key_index_state = gr.State(current_key_index)

    # Control Panel
    with gr.Row():
        with gr.Column(scale=8):
            msg = gr.Textbox(
                placeholder="Nh·∫≠p c√¢u h·ªèi ho·∫∑c y√™u c·∫ßu c·ªßa b·∫°n ·ªü ƒë√¢y...",
                lines=2,
                max_lines=5,
                label="Tin nh·∫Øn",
                container=False,
                show_label=False,
            )
        with gr.Column(scale=1, min_width=80):
            send_btn = gr.Button("G·ª≠i", variant="primary", size="sm")
        with gr.Column(scale=1, min_width=80):
            clear_btn = gr.Button("üóëÔ∏è X√≥a", variant="secondary", size="sm")

    # Hi·ªÉn th·ªã tr·∫°ng th√°i Key
    with gr.Accordion("‚ìò Tr·∫°ng th√°i API", open=False):
         key_status_display = gr.Markdown(f"S·∫µn s√†ng s·ª≠ d·ª•ng Key #{current_key_index + 1} / {len(API_KEYS) if API_KEYS else 0}", elem_id="key-status")

    # --- K·∫øt n·ªëi s·ª± ki·ªán ---
    def submit_message(message, history, key_idx_state):
        yield from respond(message, history)
        new_key_idx = current_key_index
        key_info = f"ƒêang d√πng Key #{new_key_idx + 1} / {len(API_KEYS) if API_KEYS else 0}"
        # C·∫ßn tr·∫£ v·ªÅ m·ªôt b·∫£n c·∫≠p nh·∫≠t Gradio cho Markdown
        yield gr.Markdown(value=key_info)

    submit_event = msg.submit(
        submit_message,
        inputs=[msg, chat_history_state, key_index_state],
        # msg, chatbot, chat_history_state ƒë∆∞·ª£c c·∫≠p nh·∫≠t b·ªüi yield from respond
        # key_status_display ƒë∆∞·ª£c c·∫≠p nh·∫≠t b·ªüi yield gr.Markdown cu·ªëi c√πng
        outputs=[msg, chatbot, chat_history_state, key_status_display]
    )
    click_event = send_btn.click(
        submit_message,
        inputs=[msg, chat_history_state, key_index_state],
        outputs=[msg, chatbot, chat_history_state, key_status_display]
    )

    # H√†m x√≥a chat
    def clear_chat_func():
        global current_key_index
        key_info = f"ƒêang d√πng Key #{current_key_index + 1} / {len(API_KEYS) if API_KEYS else 0}"
        # C·∫≠p nh·∫≠t tr·∫°ng th√°i key v√† x√≥a c√°c th√†nh ph·∫ßn kh√°c
        return "", [], gr.Markdown(value=key_info) # Tr·∫£ v·ªÅ update cho Markdown

    clear_btn.click(
        clear_chat_func,
        outputs=[msg, chatbot, chat_history_state, key_status_display],
        queue=False
    )

# ================= CH·∫†Y ·ª®NG D·ª§NG =================
if __name__ == "__main__":
    if not API_KEYS:
        print("\n" + "="*50)
        print("‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y API Key h·ª£p l·ªá n√†o trong danh s√°ch `API_KEYS`.")
        print("   Vui l√≤ng ch·ªânh s·ª≠a file app.py v√† th√™m c√°c API Key c·ªßa b·∫°n.")
        print("="*50 + "\n")

    print("ƒêang kh·ªüi ch·∫°y Gradio UI...")
    demo.queue().launch(
        server_name='0.0.0.0',
        server_port=int(os.environ.get('PORT', 7860)),
        share=False,
        debug=False,
        favicon_path="https://i.ibb.co/3yRk2L2/ai-icon.png"
    )
    print("Gradio UI ƒë√£ kh·ªüi ch·∫°y.")
