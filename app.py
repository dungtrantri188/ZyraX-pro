# -*- coding: utf-8 -*-
import os
import sys
import time
import random
import gradio as gr
import requests
import google.generativeai as genai
from google.api_core import exceptions as google_exceptions

# --- API Keys (embedded directly) ---
# Gemini API Key (hard-coded, be aware of security risk)
API_KEY = "AIzaSyBybfBSDLx39DdnZbHyLbd21tQAdfHtbeE"
# Serper.dev Key for web search (hard-coded, replace with your actual key)
SERPER_API_KEY = "badc5bf766d5e6d1f7779b7acf357e972c488a17"

# --- Configure Google AI ---
genai_configured = False
if not API_KEY:
    print("[ERROR] GOOGLE_API_KEY missing in code.")
else:
    print("[INFO] Configuring Google AI...")
    try:
        genai.configure(api_key=API_KEY)
        genai_configured = True
        print("[OK] Google AI configured successfully.")
    except Exception as e:
        print(f"[ERROR] Failed to configure Google AI: {e}")
        genai_configured = False

# --- Model config ---
MODEL_NAME_CHAT = "gemini-2.5-flash-preview-04-17"
print(f"Using model: {MODEL_NAME_CHAT}")

# --- Helper: Format API errors ---
def format_api_error(e):
    error_message = str(e)
    error_type = type(e).__name__
    print(f"[ERROR] API call failed: {error_type} - {error_message}")
    if isinstance(e, google_exceptions.PermissionDenied):
        if "API key not valid" in error_message or "API_KEY_INVALID" in error_message:
            return "‚ùå L·ªói: API Key ƒë∆∞·ª£c c·∫•u h√¨nh nh∆∞ng Google t·ª´ ch·ªëi khi s·ª≠ d·ª•ng (API_KEY_INVALID)."
        else:
            return f"‚ùå L·ªói: Permission Denied for model {MODEL_NAME_CHAT}."
    elif isinstance(e, google_exceptions.InvalidArgument) and "API key not valid" in error_message:
        return "‚ùå L·ªói: Invalid API Key."
    elif isinstance(e, google_exceptions.NotFound):
        return f"‚ùå L·ªói: Model {MODEL_NAME_CHAT} not found."
    elif isinstance(e, google_exceptions.ResourceExhausted):
        return "‚ùå L·ªói: Quota exceeded."
    elif isinstance(e, google_exceptions.DeadlineExceeded):
        return "‚ùå L·ªói: Request timeout."
    elif isinstance(e, AttributeError) and "start_chat" in error_message:
        return f"‚ùå L·ªói: Method start_chat not supported by model {MODEL_NAME_CHAT}."
    else:
        return f"‚ùå L·ªói g·ªçi AI ({error_type}): {error_message}"

# --- Web search helper using Serper.dev ---
def search_web(query):
    headers = {
        "X-API-KEY": SERPER_API_KEY,
        "Content-Type": "application/json"
    }
    payload = {"q": query}
    try:
        resp = requests.post("https://google.serper.dev/search", headers=headers, json=payload, timeout=10)
        data = resp.json()
    except Exception as e:
        print(f"[ERROR] Web search failed: {e}")
        return None

    summaries = []
    for result in data.get("organic", [])[:3]:
        title = result.get("title")
        snippet = result.get("snippet")
        link = result.get("link")
        summaries.append(f"- {title} ({link}): {snippet}")
    return "\n".join(summaries)

# --- Large cycling emojis ---
LARGE_CYCLING_EMOJIS = [
    # ... same list as before ...
]

# --- Gradio callback ---
def respond(message, chat_history_state):
    if not genai_configured:
        err = "‚ùå L·ªói: Google AI ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng c√°ch."
        chat_history_state.append([message, err])
        return "", chat_history_state, chat_history_state

    # Perform web search when needed
    lower = message.lower()
    if any(tok in lower for tok in ["t√¨m", "tra c·ª©u", "search", "lookup"]):
        print("[INFO] Performing web search...")
        summary = search_web(message)
        if summary:
            message = f"(K·∫øt qu·∫£ t√¨m ki·∫øm web g·∫ßn nh·∫•t):\n{summary}\n\nY√™u c·∫ßu: {message}"
        else:
            message = f"(Kh√¥ng th·ªÉ t√¨m ki·∫øm web do l·ªói k·ªπ thu·∫≠t.)\n\n{message}"

    current = list(chat_history_state)
    gemini_history = []
    for user_msg, model_msg in current:
        if user_msg:
            gemini_history.append({'role': 'user', 'parts': [user_msg]})
        if model_msg and not model_msg.startswith("‚ùå") and not model_msg.startswith("‚ö†Ô∏è"):
            gemini_history.append({'role': 'model', 'parts': [model_msg]})

    current.append([message, ""])
    idx = len(current) - 1
    full_text = ""
    emoji_idx = 0

    try:
        model = genai.GenerativeModel(MODEL_NAME_CHAT)
        chat = model.start_chat(history=gemini_history)
        resp_stream = chat.send_message(message, stream=True)
        for chunk in resp_stream:
            txt = getattr(chunk, 'text', '') or ''
            for c in txt:
                full_text += c
                emoji = LARGE_CYCLING_EMOJIS[emoji_idx % len(LARGE_CYCLING_EMOJIS)]
                emoji_idx += 1
                current[idx][1] = full_text + f" {emoji}"
                yield "", current, current
                time.sleep(0.02)
        current[idx][1] = full_text
        yield "", current, current
        print("[OK] Stream complete.")
    except Exception as e:
        err = format_api_error(e)
        current[idx][1] = err
        yield "", current, current

# --- Gradio UI ---
custom_css = """
@import url('https://fonts.googleapis.com/css2?family=Nunito:wght@800&display=swap');
.gradio-container .chatbot .message.bot { font-family: 'Nunito'; font-weight:800; font-size:1.8em; }
.gradio-container .chatbot .message.user { font-size:1.8em; }
"""

with gr.Blocks(theme=gr.themes.Default(), css=custom_css) as demo:
    gr.Markdown("## ZyRa X with Web Search")
    chatbot = gr.Chatbot(type='tuples', height=500)
    state = gr.State([])
    msg = gr.Textbox(placeholder="Nh·∫≠p c√¢u h·ªèi...", scale=4)
    send = gr.Button("G·ª≠i")
    clear = gr.Button("üóëÔ∏è X√≥a")

    msg.submit(respond, [msg, state], [msg, chatbot, state])
    send.click(respond, [msg, state], [msg, chatbot, state])
    clear.click(lambda: ("", [], []), [], [msg, chatbot, state], queue=False)

if __name__ == "__main__":
    port = int(os.environ.get('PORT', 7860))
    demo.queue().launch(server_name='0.0.0.0', server_port=port, debug=False)
