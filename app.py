# -*- coding: utf-8 -*-
import os
import sys
import time
import random # ƒê·∫£m b·∫£o ƒë√£ import random
import gradio as gr
import google.generativeai as genai
from google.api_core import exceptions as google_exceptions

# --- API Key (V·∫™N C√ì R·ª¶I RO B·∫¢O M·∫¨T CAO KHI ƒê·ªÇ TR·ª∞C TI·∫æP TRONG CODE) ---
# C·∫¢NH B√ÅO: ƒê·ªÉ API Key tr·ª±c ti·∫øp trong code l√† r·∫•t kh√¥ng an to√†n.
API_KEY = "AIzaSyBybfBSDLx39DdnZbHyLbd21tQAdfHtbeE" # <-- R·ª¶I RO B·∫¢O M·∫¨T CAO

genai_configured = False
# 1) Ki·ªÉm tra v√† c·∫•u h√¨nh API Key t·ª´ code
if not API_KEY:
    print("[ERROR] API Key b·ªã thi·∫øu trong code.]")
else:
    print("[INFO] API Key ƒë∆∞·ª£c t·∫£i tr·ª±c ti·∫øp t·ª´ code.")
    print("ƒêang c·∫•u h√¨nh Google AI...")
    try:
        genai.configure(api_key=API_KEY)
        genai_configured = True
        print("[OK] Google AI ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh th√†nh c√¥ng (c√∫ ph√°p).")
    except Exception as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ c·∫•u h√¨nh Google AI ngay c·∫£ v·ªõi c√∫ ph√°p: {e}")
        genai_configured = False

# 2) Model v√† H√†m tr·ª£ gi√∫p ƒë·ªãnh d·∫°ng l·ªói
MODEL_NAME_CHAT = "gemini-2.5-pro-exp-03-25" # Model theo y√™u c·∫ßu tr∆∞·ªõc
print(f"S·ª≠ d·ª•ng model chat: {MODEL_NAME_CHAT}")

def format_api_error(e):
    # ... (H√†m format_api_error gi·ªØ nguy√™n nh∆∞ tr∆∞·ªõc) ...
    error_message = str(e)
    error_type = type(e).__name__
    print(f"[ERROR] L·ªói khi g·ªçi API: {error_type} - {error_message}")

    if isinstance(e, google_exceptions.PermissionDenied):
        if "API key not valid" in error_message or "API_KEY_INVALID" in error_message:
             return f"‚ùå L·ªói: API Key ƒë∆∞·ª£c c·∫•u h√¨nh nh∆∞ng Google t·ª´ ch·ªëi khi s·ª≠ d·ª•ng (API_KEY_INVALID) cho model '{MODEL_NAME_CHAT}'. C√≥ th·ªÉ key ƒë√£ b·ªã v√¥ hi·ªáu h√≥a."
        else:
             return f"‚ùå L·ªói: T·ª´ ch·ªëi quy·ªÅn truy c·∫≠p (Permission Denied) cho model '{MODEL_NAME_CHAT}'. API key c·ªßa b·∫°n c√≥ th·ªÉ kh√¥ng c√≥ quy·ªÅn s·ª≠ d·ª•ng model n√†y ho·∫∑c ch∆∞a b·∫≠t 'Generative Language API' trong Google Cloud."
    elif isinstance(e, google_exceptions.InvalidArgument) and "API key not valid" in error_message:
        return "‚ùå L·ªói: API Key kh√¥ng h·ª£p l·ªá (InvalidArgument). Key cung c·∫•p kh√¥ng ƒë√∫ng ho·∫∑c ƒë√£ b·ªã v√¥ hi·ªáu h√≥a."
    elif isinstance(e, google_exceptions.NotFound):
         return f"‚ùå L·ªói: Model '{MODEL_NAME_CHAT}' kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng t·ªìn t·∫°i v·ªõi API key c·ªßa b·∫°n. H√£y ki·ªÉm tra l·∫°i t√™n model ho·∫∑c quy·ªÅn truy c·∫≠p."
    elif isinstance(e, google_exceptions.ResourceExhausted):
         return "‚ùå L·ªói: ƒê√£ v∆∞·ª£t qu√° H·∫°n ng·∫°ch API (Quota) ho·∫∑c T√†i nguy√™n ƒë√£ c·∫°n ki·ªát (429). Vui l√≤ng th·ª≠ l·∫°i sau."
    elif isinstance(e, google_exceptions.DeadlineExceeded):
         return "‚ùå L·ªói: Y√™u c·∫ßu v∆∞·ª£t qu√° th·ªùi gian ch·ªù (Timeout/Deadline Exceeded/504)."
    elif isinstance(e, AttributeError) and "start_chat" in error_message:
         return f"‚ùå L·ªói: Model '{MODEL_NAME_CHAT}' c√≥ th·ªÉ kh√¥ng h·ªó tr·ª£ ph∆∞∆°ng th·ª©c `start_chat` (th∆∞·ªùng d√πng cho chat)."
    else:
         return f"‚ùå L·ªói khi g·ªçi AI ({error_type}): {error_message}"

# --- Danh s√°ch Emoji L·ªõn (Gi·ªØ nguy√™n) ---
LARGE_CYCLING_EMOJIS = [
    "üòÄ", "üòÅ", "üòÇ", "ü§£", "üòÉ", "üòÑ", "üòÖ", "üòÜ", "üòâ", "üòä", "üòã", "üòé", "üòç", "üòò", "ü•∞", "üòó", "üòô", "üòö", "üôÇ", "ü§ó",
    "ü§©", "ü§î", "ü§®", "üòê", "üòë", "üò∂", "üôÑ", "üòè", "üò£", "üò•", "üòÆ", "ü§ê", "üòØ", "üò™", "üò´", "üò¥", "üòå", "üòõ", "üòú", "üòù",
    "ü§§", "üòí", "üòì", "üòî", "üòï", "üôÉ", "ü§ë", "üò≤", "‚òπÔ∏è", "üôÅ", "üòñ", "üòû", "üòü", "üò§", "üò¢", "üò≠", "üò¶", "üòß", "üò®", "üò©",
    "ü§Ø", "üò¨", "üò∞", "üò±", "ü•µ", "ü•∂", "üò≥", "ü§™", "üòµ", "ü•¥", "üò†", "üò°", "ü§¨", "üò∑", "ü§í", "ü§ï", "ü§¢", "ü§Æ", "ü§ß", "üòá",
    "ü•≥", "ü•∫", "ü§†", "ü§°", "ü§•", "ü§´", "ü§≠", "üßê", "ü§ì", "üòà", "üëø", "üëπ", "üë∫", "üíÄ", "üëª", "üëΩ", "ü§ñ", "üí©", "üò∫", "üò∏",
    "üòπ", "üòª", "üòº", "üòΩ", "üôÄ", "üòø", "üòæ", "ü´∂", "üëç", "üëé", "üëå", "ü§å", "ü§è", "‚úåÔ∏è", "ü§û", "ü§ü", "ü§ò", "ü§ô", "üëà", "üëâ",
    "üëÜ", "üñï", "üëá", "‚òùÔ∏è", "‚úã", "ü§ö", "üñêÔ∏è", "üññ", "üëã", "üôè", "üß†", "ü´Ä", "ü´Å", "ü¶∑", "ü¶¥", "üëÄ", "üëÅÔ∏è", "üëÖ", "üëÑ", "üë∂",
    "üßí", "üë¶", "üëß", "üßë", "üë±", "üë®", "üßî", "üë©", "üë†", "üëë", "üíç", "üíé", "üêµ", "üê∂", "üê∫", "üê±", "ü¶Å", "üêØ", "ü¶í", "ü¶ä",
    "ü¶ù", "üêÆ", "üê∑", "üêó", "üê≠", "üêπ", "üê∞", "üê∏", "üê®", "üêº", "üêª", "üêß", "üê¶", "üê§", "ü¶ã", "üêõ", "üêù", "üêû", "ü¶Ç", "ü¶Ä",
    "üêç", "üê¢", "üê†", "üê≥", "üê¨", "üêô", "üçé", "üçå", "üçá", "üçì", "üçï", "üçî", "üçü", "‚öΩÔ∏è", "üèÄ", "üèà", "‚öæÔ∏è", "üéæ", "üèê", "üé±",
    "üéÆ", "üé∞", "üöÄ", "‚úàÔ∏è", "üöó", "üö≤", "üì±", "üíª", "üí°", "üí∞", "üìà", "üìâ", "‚öôÔ∏è", "üîß", "üî®", "‚öîÔ∏è", "üõ°Ô∏è", "‚è≥", "‚è∞", "üéâ",
    "üéÅ", "üéà", "‚úâÔ∏è", "‚ù§Ô∏è", "üíî", "‚≠êÔ∏è", "üåü", "‚ö°Ô∏è", "üí•", "üí®", "üí¶", "üíß", "üåä", "‚òÄÔ∏è", "üåô", "‚òÅÔ∏è", "üî•", "üåà", "‚õÑÔ∏è", "‚ùÑÔ∏è"
]
# --- K·∫øt Th√∫c Danh S√°ch Emoji ---

# 3) H√†m callback Gradio
def respond(message, chat_history_state):
    if not genai_configured:
        error_msg = "‚ùå L·ªói: Google AI ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng c√°ch (API Key c√≥ v·∫•n ƒë·ªÅ ho·∫∑c c·∫•u h√¨nh th·∫•t b·∫°i)."
        if isinstance(chat_history_state, list):
             chat_history_state.append([message, error_msg])
        else:
             chat_history_state = [[message, error_msg]]
        return "", chat_history_state, chat_history_state

    current_chat_history = list(chat_history_state)
    gemini_history = []
    for user_msg, model_msg in current_chat_history:
        if user_msg and isinstance(user_msg, str):
             gemini_history.append({'role': 'user', 'parts': [user_msg]})
        if model_msg and isinstance(model_msg, str) and not model_msg.startswith("‚ùå") and not model_msg.startswith("‚ö†Ô∏è"):
             gemini_history.append({'role': 'model', 'parts': [model_msg]})

    print(f"L·ªãch s·ª≠ g·ª≠i t·ªõi Gemini: {gemini_history}")
    print(f"Prompt m·ªõi: '{message[:70]}...'")

    current_chat_history.append([message, ""])
    response_index = len(current_chat_history) - 1

    full_response_text = ""
    final_status_message = ""
    # emoji_cycle_index kh√¥ng c√≤n d√πng ƒë·ªÉ ch·ªçn emoji n·ªØa

    try:
        model = genai.GenerativeModel(MODEL_NAME_CHAT)
        chat = model.start_chat(history=gemini_history)
        response = chat.send_message(message, stream=True)

        for chunk in response:
            try:
                chunk_text = getattr(chunk, 'text', '')
                if chunk_text:
                    for char in chunk_text:
                        full_response_text += char

                        # --- THAY ƒê·ªîI: Ch·ªçn Emoji Ng·∫´u Nhi√™n ---
                        current_emoji = random.choice(LARGE_CYCLING_EMOJIS) # Ch·ªçn ng·∫´u nhi√™n t·ª´ danh s√°ch l·ªõn
                        display_text = full_response_text + f" {current_emoji}" # Th√™m emoji ng·∫´u nhi√™n
                        # --- K·∫øt Th√∫c Thay ƒê·ªïi Emoji ---

                        current_chat_history[response_index][1] = display_text
                        yield "", current_chat_history, current_chat_history

                        # T·ªëc ƒë·ªô in vƒÉn b·∫£n nhanh (gi·ªØ nguy√™n t·ª´ l·∫ßn tr∆∞·ªõc)
                        time.sleep(0.01)

                        # Hi·ªáu ·ª®ng Lag Gi·∫£ Ng·∫´u Nhi√™n (Gi·ªØ nguy√™n)
                        lag_probability = 0.005
                        if random.random() < lag_probability:
                            lag_duration = random.uniform(1.0, 1.75)
                            print(f"[INFO] Simulating high load pause for {lag_duration:.2f}s...")
                            time.sleep(lag_duration)

                else:
                    # ... (x·ª≠ l√Ω block/finish reason gi·ªØ nguy√™n nh∆∞ tr∆∞·ªõc) ...
                    block_reason = getattr(getattr(chunk, 'prompt_feedback', None), 'block_reason', None)
                    finish_reason_obj = chunk.candidates[0].finish_reason if chunk.candidates else None
                    finish_reason = finish_reason_obj.name if finish_reason_obj else None

                    reason_text = ""
                    should_stop = False
                    if block_reason:
                        reason_text, should_stop = f"Y√™u c·∫ßu/Ph·∫£n h·ªìi b·ªã ch·∫∑n ({block_reason})", True
                    elif finish_reason and finish_reason != 'STOP':
                        reason_text, should_stop = f"Ph·∫£n h·ªìi b·ªã d·ª´ng ({finish_reason})", True

                    if reason_text:
                        print(f"[WARN] {reason_text}")
                        final_status_message = f"\n‚ö†Ô∏è ({reason_text})"
                        if should_stop: break

            except Exception as inner_e:
                # ... (x·ª≠ l√Ω l·ªói inner_e gi·ªØ nguy√™n) ...
                print(f"[ERROR] L·ªói khi x·ª≠ l√Ω chunk stream: {type(inner_e).__name__} - {inner_e}")
                final_status_message = f"\n‚ö†Ô∏è (L·ªói khi x·ª≠ l√Ω ph·∫ßn ti·∫øp theo: {inner_e})"
                break

        # --- D·ªçn d·∫πp cu·ªëi c√πng (gi·ªØ nguy√™n) ---
        final_clean_text = full_response_text
        if final_status_message and final_status_message not in final_clean_text:
             final_clean_text += final_status_message
        current_chat_history[response_index][1] = final_clean_text
        yield "", current_chat_history, current_chat_history
        print("[OK] Streaming ho√†n t·∫•t." if not final_status_message else "[WARN/ERROR] Streaming k·∫øt th√∫c v·ªõi tr·∫°ng th√°i.")

    except Exception as e:
        # ... (x·ª≠ l√Ω l·ªói API ch√≠nh gi·ªØ nguy√™n) ...
        error_msg = format_api_error(e)
        current_chat_history[response_index][1] = error_msg
        yield "", current_chat_history, current_chat_history


# 4) UI Gradio (Gi·ªØ nguy√™n CSS v√† c·∫•u tr√∫c)
custom_font_and_size_css = f"""
@import url('https://fonts.googleapis.com/css2?family=Nunito:wght@800&display=swap');
/* ... (CSS gi·ªØ nguy√™n nh∆∞ tr∆∞·ªõc) ... */
.gradio-container .chatbot .message.bot {{
    font-family: 'Nunito', sans-serif !important;
    font-weight: 800 !important;
    font-size: 1.8em !important;
    line-height: 1.5 !important;
}}
.gradio-container .chatbot .message.user {{
    font-size: 1.8em !important;
    line-height: 1.5 !important;
}}
"""

with gr.Blocks(theme=gr.themes.Default(), css=custom_font_and_size_css) as demo:
    gr.Markdown("## ZyRa X - t·∫°o b·ªüi D≈©ng")
    chatbot = gr.Chatbot(
        label="Chatbot",
        height=500,
        bubble_full_width=False,
        render_markdown=True,
        latex_delimiters=[
            { "left": "$$", "right": "$$", "display": True },
            { "left": "$", "right": "$", "display": False },
        ]
    )
    chat_history_state = gr.State(value=[])
    with gr.Row():
        msg = gr.Textbox(
            placeholder="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n...",
            label="B·∫°n",
            scale=4,
            container=False
        )
        send_btn = gr.Button("G·ª≠i")
    clear_btn = gr.Button("üóëÔ∏è X√≥a cu·ªôc tr√≤ chuy·ªán")

    # --- K·∫øt n·ªëi s·ª± ki·ªán (Gi·ªØ nguy√™n) ---
    submit_event = msg.submit(
        fn=respond,
        inputs=[msg, chat_history_state],
        outputs=[msg, chatbot, chat_history_state]
    )
    click_event = send_btn.click(
        fn=respond,
        inputs=[msg, chat_history_state],
        outputs=[msg, chatbot, chat_history_state]
    )
    def clear_chat_func():
        print("[INFO] Clearing chat history.")
        return "", [], []
    clear_btn.click(
        fn=clear_chat_func,
        inputs=None,
        outputs=[msg, chatbot, chat_history_state],
        queue=False
    )

# 5) Ch·∫°y ·ª©ng d·ª•ng Gradio (Gi·ªØ nguy√™n)
print("ƒêang kh·ªüi ch·∫°y Gradio UI...")
demo.queue().launch(
    server_name='0.0.0.0',
    server_port=int(os.environ.get('PORT', 7860)),
    debug=False
)
print("Gradio UI ƒë√£ kh·ªüi ch·∫°y.")
