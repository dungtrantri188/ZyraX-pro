# -*- coding: utf-8 -*-
import os
import sys
import time
import random
import gradio as gr
import google.generativeai as genai
from google.api_core import exceptions as google_exceptions
import unicodedata # Th√™m ƒë·ªÉ ki·ªÉm tra emoji (t√πy ch·ªçn)

# --- Th√™m import cho th∆∞ vi·ªán emoji v√† random ---
try:
    import emoji
except ImportError:
    print("[ERROR] Th∆∞ vi·ªán 'emoji' ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.")
    print("Vui l√≤ng ch·∫°y: pip install emoji")
    print("S·ª≠ d·ª•ng danh s√°ch emoji m·∫∑c ƒë·ªãnh gi·ªõi h·∫°n.")
    emoji = None # ƒê√°nh d·∫•u l√† kh√¥ng c√≥ th∆∞ vi·ªán
import random
# --- K·∫øt th√∫c th√™m import ---


# --- API Key (V·∫™N C√ì R·ª¶I RO B·∫¢O M·∫¨T CAO KHI ƒê·ªÇ TR·ª∞C TI·∫æP TRONG CODE) ---
API_KEY = "AIzaSyBybfBSDLx39DdnZbHyLbd21tQAdfHtbeE" # <-- R·ª¶I RO B·∫¢O M·∫¨T

genai_configured = False
# 1) Ki·ªÉm tra v√† c·∫•u h√¨nh API Key t·ª´ code (Gi·ªØ nguy√™n)
if not API_KEY:
    print("[ERROR] API Key b·ªã thi·∫øu trong code.]")
else:
    print("[INFO] API Key ƒë∆∞·ª£c t·∫£i tr·ª±c ti·∫øp t·ª´ code.")
    print("ƒêang c·∫•u h√¨nh Google AI...")
    try:
        genai.configure(api_key=API_KEY)
        genai_configured = True
        print("[OK] Google AI ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh th√†nh c√¥ng (c√∫ ph√°p).")
    except Exception as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ c·∫•u h√¨nh Google AI ngay c·∫£ v·ªõi c√∫ ph√°p: {e}")
        genai_configured = False

# 2) Model v√† H√†m tr·ª£ gi√∫p ƒë·ªãnh d·∫°ng l·ªói (Gi·ªØ nguy√™n)
MODEL_NAME_CHAT = "Gemini-2.5-Pro-Exp-03-25" # S·ª≠ d·ª•ng model m·ªõi h∆°n n·∫øu c√≥ th·ªÉ
# MODEL_NAME_CHAT = "gemini-pro" # Ho·∫∑c model ·ªïn ƒë·ªãnh h∆°n
print(f"S·ª≠ d·ª•ng model chat: {MODEL_NAME_CHAT}")

def format_api_error(e):
    # ... (H√†m format_api_error gi·ªØ nguy√™n nh∆∞ trong code g·ªëc c·ªßa b·∫°n) ...
    error_message = str(e)
    error_type = type(e).__name__
    print(f"[ERROR] L·ªói khi g·ªçi API: {error_type} - {error_message}")

    if isinstance(e, google_exceptions.PermissionDenied):
        if "API key not valid" in error_message or "API_KEY_INVALID" in error_message:
             return f"‚ùå L·ªói: API Key ƒë∆∞·ª£c c·∫•u h√¨nh nh∆∞ng Google t·ª´ ch·ªëi khi s·ª≠ d·ª•ng (API_KEY_INVALID) cho model '{MODEL_NAME_CHAT}'. C√≥ th·ªÉ key ƒë√£ b·ªã v√¥ hi·ªáu h√≥a ho·∫∑c kh√¥ng c√≥ quy·ªÅn truy c·∫≠p model n√†y."
        elif "User location is not supported" in error_message:
             return f"‚ùå L·ªói: V·ªã tr√≠ c·ªßa b·∫°n kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£ ƒë·ªÉ s·ª≠ d·ª•ng API n√†y (User location is not supported)."
        else:
             return f"‚ùå L·ªói: T·ª´ ch·ªëi quy·ªÅn truy c·∫≠p (Permission Denied) cho model '{MODEL_NAME_CHAT}'. API key c·ªßa b·∫°n c√≥ th·ªÉ kh√¥ng c√≥ quy·ªÅn s·ª≠ d·ª•ng model n√†y ho·∫∑c ch∆∞a b·∫≠t 'Generative Language API' trong Google Cloud."
    elif isinstance(e, google_exceptions.InvalidArgument) and "API key not valid" in error_message:
        return "‚ùå L·ªói: API Key kh√¥ng h·ª£p l·ªá (InvalidArgument). Key cung c·∫•p kh√¥ng ƒë√∫ng ho·∫∑c ƒë√£ b·ªã v√¥ hi·ªáu h√≥a."
    elif isinstance(e, google_exceptions.NotFound):
         return f"‚ùå L·ªói: Model '{MODEL_NAME_CHAT}' kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng t·ªìn t·∫°i v·ªõi API key c·ªßa b·∫°n."
    elif isinstance(e, google_exceptions.ResourceExhausted):
         return "‚ùå L·ªói: ƒê√£ v∆∞·ª£t qu√° H·∫°n ng·∫°ch API (Quota) ho·∫∑c T√†i nguy√™n ƒë√£ c·∫°n ki·ªát (429). Vui l√≤ng th·ª≠ l·∫°i sau."
    elif isinstance(e, google_exceptions.DeadlineExceeded):
         return "‚ùå L·ªói: Y√™u c·∫ßu v∆∞·ª£t qu√° th·ªùi gian ch·ªù (Timeout/Deadline Exceeded/504)."
    elif isinstance(e, AttributeError) and "'GenerativeModel' object has no attribute 'start_chat'" in error_message:
         # L·ªói n√†y th∆∞·ªùng x·∫£y ra n·∫øu model kh√¥ng h·ªó tr·ª£ chat ho·∫∑c c√≥ v·∫•n ƒë·ªÅ c·∫•u h√¨nh
         return f"‚ùå L·ªói: Model '{MODEL_NAME_CHAT}' d∆∞·ªùng nh∆∞ kh√¥ng h·ªó tr·ª£ ph∆∞∆°ng th·ª©c `start_chat` ho·∫∑c c√≥ l·ªói c·∫•u h√¨nh genai."
    elif isinstance(e, google_exceptions.InternalServerError):
         return f"‚ùå L·ªói: L·ªói m√°y ch·ªß n·ªôi b·ªô t·ª´ Google (Internal Server Error/500). Vui l√≤ng th·ª≠ l·∫°i sau."
    elif isinstance(e, google_exceptions.ServiceUnavailable):
         return f"‚ùå L·ªói: D·ªãch v·ª• Google AI t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng (Service Unavailable/503). Vui l√≤ng th·ª≠ l·∫°i sau."
    else:
         return f"‚ùå L·ªói khi g·ªçi AI ({error_type}): {error_message}"


# --- T·∫†O DANH S√ÅCH EMOJI L·ªöN T·ª™ TH∆Ø VI·ªÜN ---
ALL_AVAILABLE_EMOJIS = []
if emoji:
    try:
        # L·∫•y t·∫•t c·∫£ emoji t·ª´ th∆∞ vi·ªán (keys l√† k√Ω t·ª± emoji)
        # L·ªçc c√°c emoji ng√¥n ng·ªØ 'en' ƒë·ªÉ c√≥ b·ªô chu·∫©n nh·∫•t
        emoji_dict_en = emoji.EMOJI_DATA
        all_emoji_chars = list(emoji_dict_en.keys())

        # T√πy ch·ªçn: L·ªçc b·ªè c√°c emoji kh√¥ng ph·ªï bi·∫øn ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát (c√≥ th·ªÉ g√¢y l·ªói hi·ªÉn th·ªã)
        # V√≠ d·ª•: Ch·ªâ gi·ªØ l·∫°i nh·ªØng k√Ω t·ª± ƒë∆°n v√† thu·ªôc danh m·ª•c 'So' (Symbol, other)
        # filtered_emojis = [
        #     e for e in all_emoji_chars
        #     if len(e) == 1 and unicodedata.category(e) == 'So'
        # ]
        # ALL_AVAILABLE_EMOJIS = filtered_emojis

        # Hi·ªán t·∫°i d√πng t·∫•t c·∫£, ch·∫•p nh·∫≠n r·ªßi ro hi·ªÉn th·ªã
        ALL_AVAILABLE_EMOJIS = all_emoji_chars

        # X√°o tr·ªôn danh s√°ch ƒë·ªÉ thay ƒë·ªïi ng·∫´u nhi√™n h∆°n
        random.shuffle(ALL_AVAILABLE_EMOJIS)
        print(f"[INFO] ƒê√£ t·∫°o danh s√°ch g·ªìm {len(ALL_AVAILABLE_EMOJIS)} emoji t·ª´ th∆∞ vi·ªán.")
        if len(ALL_AVAILABLE_EMOJIS) < 2000:
            print("[WARN] S·ªë l∆∞·ª£ng emoji t√¨m th·∫•y √≠t h∆°n mong ƒë·ª£i (< 2000).")

    except Exception as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ t·∫°o danh s√°ch emoji t·ª´ th∆∞ vi·ªán: {e}")
        # S·ª≠ d·ª•ng danh s√°ch d·ª± ph√≤ng nh·ªè n·∫øu l·ªói
        ALL_AVAILABLE_EMOJIS = list("üòÄüòÅüòÇü§£üòÉüòÑüòÖüòÜüòâüòäüòãüòéüòçüòòü•∞üòóüòôüòöüôÇü§óü§©ü§îü§®üòêüòëüò∂üôÑüòèüò£üò•üòÆü§êüòØüò™üò´üò¥üòåüòõüòúüòùü§§üòíüòìüòîüòïüôÉü§ëüò≤‚òπüôÅüòñüòûüòüüò§üò¢üò≠üò¶üòßüò®üò©ü§Øüò¨üò∞üò±ü•µü•∂üò≥ü§™üòµü•¥üò†üò°ü§¨üò∑ü§íü§ïü§¢ü§Æü§ßüòáü•≥ü•∫ü§†ü§°ü§•ü§´ü§≠üßêü§ìüòàüëøüëπüë∫üíÄüëªüëΩü§ñüí©üò∫üò∏üòπüòªüòºüòΩüôÄüòøüòæüëçüëé")
        print(f"[WARN] S·ª≠ d·ª•ng danh s√°ch emoji d·ª± ph√≤ng ({len(ALL_AVAILABLE_EMOJIS)}).")
else:
    # Danh s√°ch d·ª± ph√≤ng n·∫øu th∆∞ vi·ªán emoji kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t
    ALL_AVAILABLE_EMOJIS = list("üòÄüòÅüòÇü§£üòÉüòÑüòÖüòÜüòâüòäüòãüòéüòçüòòü•∞üòóüòôüòöüôÇü§óü§©ü§îü§®üòêüòëüò∂üôÑüòèüò£üò•üòÆü§êüòØüò™üò´üò¥üòåüòõüòúüòùü§§üòíüòìüòîüòïüôÉü§ëüò≤‚òπüôÅüòñüòûüòüüò§üò¢üò≠üò¶üòßüò®üò©ü§Øüò¨üò∞üò±ü•µü•∂üò≥ü§™üòµü•¥üò†üò°ü§¨üò∑ü§íü§ïü§¢ü§Æü§ßüòáü•≥ü•∫ü§†ü§°ü§•ü§´ü§≠üßêü§ìüòàüëøüëπüë∫üíÄüëªüëΩü§ñüí©üò∫üò∏üòπüòªüòºüòΩüôÄüòøüòæüëçüëé")
    print(f"[WARN] S·ª≠ d·ª•ng danh s√°ch emoji d·ª± ph√≤ng ({len(ALL_AVAILABLE_EMOJIS)}) do thi·∫øu th∆∞ vi·ªán 'emoji'.")

# ƒê·∫£m b·∫£o danh s√°ch kh√¥ng bao gi·ªù r·ªóng
if not ALL_AVAILABLE_EMOJIS:
    ALL_AVAILABLE_EMOJIS = ["‚ùì", "‚ùó"]
# --- K·∫æT TH√öC T·∫†O DANH S√ÅCH EMOJI ---


# 3) H√†m callback Gradio (S·ª≠ d·ª•ng danh s√°ch emoji l·ªõn v√† t·ªëc ƒë·ªô nhanh h∆°n)
def respond(message, chat_history_state):
    if not genai_configured:
        error_msg = "‚ùå L·ªói: Google AI ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng c√°ch (API Key c√≥ v·∫•n ƒë·ªÅ ho·∫∑c c·∫•u h√¨nh th·∫•t b·∫°i)."
        # ƒê·∫£m b·∫£o chat_history_state l√† list tr∆∞·ªõc khi append
        if not isinstance(chat_history_state, list):
            chat_history_state = []
        chat_history_state.append((message, error_msg)) # S·ª≠ d·ª•ng tuple (user, bot)
        return "", chat_history_state, chat_history_state

    # --- Kh·ªüi t·∫°o l·ªãch s·ª≠ ---
    # ƒê·∫£m b·∫£o chat_history_state l√† list, n·∫øu kh√¥ng th√¨ kh·ªüi t·∫°o r·ªóng
    if not isinstance(chat_history_state, list):
         current_chat_history = []
         print("[WARN] chat_history_state kh√¥ng ph·∫£i list, ƒë√£ reset.")
    else:
         # Chuy·ªÉn ƒë·ªïi t·ª´ list c·ªßa tuples sang list c·ªßa lists ƒë·ªÉ d·ªÖ ch·ªânh s·ª≠a
         current_chat_history = [list(item) for item in chat_history_state]

    # --- X√¢y d·ª±ng l·ªãch s·ª≠ cho Gemini ---
    gemini_history = []
    for user_msg, model_msg in current_chat_history:
        # B·ªè qua c√°c c·∫∑p c√≥ l·ªói ho·∫∑c kh√¥ng h·ª£p l·ªá
        if user_msg and isinstance(user_msg, str):
            gemini_history.append({'role': 'user', 'parts': [user_msg]})
        if model_msg and isinstance(model_msg, str) and not model_msg.startswith("‚ùå") and not model_msg.startswith("‚ö†Ô∏è"):
            # Ch·ªâ th√™m ph·∫£n h·ªìi h·ª£p l·ªá c·ªßa model v√†o l·ªãch s·ª≠
            gemini_history.append({'role': 'model', 'parts': [model_msg]})

    print(f"L·ªãch s·ª≠ g·ª≠i t·ªõi Gemini (size={len(gemini_history)}): {str(gemini_history)[:200]}...") # In ng·∫Øn g·ªçn
    print(f"Prompt m·ªõi: '{message[:70]}...'")

    # Th√™m tin nh·∫Øn m·ªõi c·ªßa ng∆∞·ªùi d√πng v√†o cu·ªëi (t·∫°m th·ªùi ƒë·ªÉ hi·ªÉn th·ªã)
    current_chat_history.append([message, ""]) # Th√™m d∆∞·ªõi d·∫°ng list [user, bot]
    response_index = len(current_chat_history) - 1 # V·ªã tr√≠ c·ªßa ph·∫£n h·ªìi ƒëang ch·ªù

    full_response_text = ""
    final_status_message = ""
    emoji_cycle_index = 0 # Reset ch·ªâ s·ªë emoji cho m·ªói l·∫ßn g·ªçi

    try:
        model = genai.GenerativeModel(MODEL_NAME_CHAT)
        chat = model.start_chat(history=gemini_history)
        # --- C·∫•u h√¨nh an to√†n (T√πy ch·ªçn) ---
        safety_settings = [
            {
                "category": "HARM_CATEGORY_HARASSMENT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
        ]
        # --- G·ª≠i tin nh·∫Øn v·ªõi stream v√† c·∫•u h√¨nh an to√†n ---
        response = chat.send_message(
            message,
            stream=True,
            safety_settings=safety_settings
        )

        for chunk in response:
            try:
                chunk_text = getattr(chunk, 'text', '')
                if chunk_text:
                    for char in chunk_text:
                        full_response_text += char

                        # --- Thay ƒë·ªïi Emoji Li√™n T·ª•c t·ª´ danh s√°ch L·ªöN ---
                        if ALL_AVAILABLE_EMOJIS: # Ki·ªÉm tra xem danh s√°ch c√≥ emoji kh√¥ng
                            current_emoji = ALL_AVAILABLE_EMOJIS[emoji_cycle_index % len(ALL_AVAILABLE_EMOJIS)]
                            emoji_cycle_index += 1
                            display_text = full_response_text + f" {current_emoji}" # Th√™m emoji ƒëang thay ƒë·ªïi
                        else:
                            display_text = full_response_text + "..." # Ho·∫∑c d·∫•u ba ch·∫•m n·∫øu kh√¥ng c√≥ emoji

                        # --- C·∫≠p nh·∫≠t UI ---
                        # Chuy·ªÉn ƒë·ªïi l·∫°i th√†nh tuple tr∆∞·ªõc khi yield n·∫øu Gradio y√™u c·∫ßu
                        history_tuples = [tuple(item) for item in current_chat_history]
                        history_tuples[response_index] = (history_tuples[response_index][0], display_text) # C·∫≠p nh·∫≠t ph·∫ßn bot message

                        yield "", history_tuples, history_tuples # Yield history d·∫°ng list c·ªßa tuples
                        # --- GI·∫¢M TH·ªúI GIAN SLEEP ƒê·ªÇ NHANH H∆†N ---
                        time.sleep(0.01) # Gi·∫£m t·ª´ 0.02 xu·ªëng 0.01
                        # --- K·∫æT TH√öC GI·∫¢M TH·ªúI GIAN SLEEP ---

                        # --- Hi·ªáu ·ª®ng Lag Gi·∫£ Ng·∫´u Nhi√™n (Gi·ªØ nguy√™n) ---
                        lag_probability = 0.005
                        if random.random() < lag_probability:
                            lag_duration = random.uniform(0.8, 1.5) # Gi·∫£m nh·∫π th·ªùi gian lag
                            print(f"[INFO] Simulating high load pause for {lag_duration:.2f}s...")
                            time.sleep(lag_duration)
                        # --- K·∫øt Th√∫c Hi·ªáu ·ª®ng Lag ---

                # --- X·ª≠ l√Ω Block/Finish Reason (C·∫£i thi·ªán) ---
                # C√°ch l·∫•y l√Ω do ch·∫∑n/k·∫øt th√∫c c√≥ th·ªÉ kh√°c nhau gi·ªØa c√°c phi√™n b·∫£n API/SDK
                block_reason = None
                finish_reason = None
                try:
                    # Th·ª≠ l·∫•y t·ª´ prompt_feedback tr∆∞·ªõc (th∆∞·ªùng cho block)
                    block_reason = chunk.prompt_feedback.block_reason.name if chunk.prompt_feedback else None
                except AttributeError:
                    pass # B·ªè qua n·∫øu kh√¥ng c√≥ prompt_feedback

                try:
                     # Th·ª≠ l·∫•y t·ª´ candidates (th∆∞·ªùng cho finish reason)
                    if chunk.candidates:
                         # L·∫•y finish_reason t·ª´ candidate ƒë·∫ßu ti√™n
                         finish_reason_enum = chunk.candidates[0].finish_reason
                         # Chuy·ªÉn enum th√†nh string (n·∫øu c·∫ßn)
                         finish_reason = finish_reason_enum.name if hasattr(finish_reason_enum, 'name') else str(finish_reason_enum)
                except (AttributeError, IndexError):
                     pass # B·ªè qua n·∫øu kh√¥ng c√≥ candidates ho·∫∑c finish_reason

                reason_text = ""
                should_stop = False
                if block_reason and block_reason != 'BLOCK_REASON_UNSPECIFIED':
                    reason_text, should_stop = f"Y√™u c·∫ßu/Ph·∫£n h·ªìi b·ªã ch·∫∑n ({block_reason})", True
                elif finish_reason and finish_reason not in ['STOP', 'FINISH_REASON_UNSPECIFIED', 'UNKNOWN']: # C√°c l√Ω do d·ª´ng b√¨nh th∆∞·ªùng
                    # C√°c l√Ω do kh√°c STOP l√† b·∫•t th∆∞·ªùng (SAFETY, RECITATION, MAX_TOKENS, OTHER)
                    reason_text, should_stop = f"Ph·∫£n h·ªìi b·ªã d·ª´ng ({finish_reason})", True

                if reason_text:
                    print(f"[WARN] {reason_text}")
                    # Ch·ªâ th√™m n·∫øu ch∆∞a c√≥ trong tin nh·∫Øn cu·ªëi
                    if reason_text not in final_status_message:
                        final_status_message += f"\n‚ö†Ô∏è ({reason_text})"
                    if should_stop:
                        break # D·ª´ng x·ª≠ l√Ω stream n·∫øu b·ªã ch·∫∑n ho·∫∑c d·ª´ng b·∫•t th∆∞·ªùng

            except StopIteration:
                 print("[INFO] Stream k·∫øt th√∫c (StopIteration).")
                 break # K·∫øt th√∫c v√≤ng l·∫∑p stream m·ªôt c√°ch b√¨nh th∆∞·ªùng
            except Exception as inner_e:
                print(f"[ERROR] L·ªói khi x·ª≠ l√Ω chunk stream: {type(inner_e).__name__} - {inner_e}")
                # Ch·ªâ th√™m n·∫øu ch∆∞a c√≥ trong tin nh·∫Øn cu·ªëi
                error_info = f"L·ªói x·ª≠ l√Ω chunk: {inner_e}"
                if error_info not in final_status_message:
                    final_status_message += f"\n‚ö†Ô∏è ({error_info})"
                # Kh√¥ng n√™n break ·ªü ƒë√¢y tr·ª´ khi l·ªói nghi√™m tr·ªçng, ƒë·ªÉ th·ª≠ x·ª≠ l√Ω chunk ti·∫øp theo
                # break

        # --- D·ªçn d·∫πp cu·ªëi c√πng ---
        final_clean_text = full_response_text.strip() # X√≥a kho·∫£ng tr·∫Øng th·ª´a
        if final_status_message and final_status_message not in final_clean_text:
             final_clean_text += final_status_message

        # C·∫≠p nh·∫≠t l·∫ßn cu·ªëi v√†o history d·∫°ng list
        current_chat_history[response_index][1] = final_clean_text
        # Chuy·ªÉn ƒë·ªïi l·∫°i history sang d·∫°ng list c·ªßa tuples cho Gradio
        final_history_tuples = [tuple(item) for item in current_chat_history]

        yield "", final_history_tuples, final_history_tuples # Yield history cu·ªëi c√πng
        print("[OK] Streaming ho√†n t·∫•t." if not final_status_message else "[WARN/ERROR] Streaming k·∫øt th√∫c v·ªõi tr·∫°ng th√°i.")

    except AttributeError as e:
         # X·ª≠ l√Ω l·ªói AttributeError c·ª• th·ªÉ h∆°n (v√≠ d·ª•: start_chat kh√¥ng t·ªìn t·∫°i)
         error_msg = format_api_error(e)
         # ƒê·∫£m b·∫£o current_chat_history l√† list ƒë·ªÉ c√≥ th·ªÉ truy c·∫≠p index
         if isinstance(current_chat_history, list) and len(current_chat_history) > response_index:
             current_chat_history[response_index][1] = error_msg
         else: # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p history kh√¥ng h·ª£p l·ªá
             current_chat_history.append([message, error_msg])
         final_history_tuples = [tuple(item) for item in current_chat_history]
         yield "", final_history_tuples, final_history_tuples

    except Exception as e:
        # X·ª≠ l√Ω l·ªói API ch√≠nh
        error_msg = format_api_error(e)
         # ƒê·∫£m b·∫£o current_chat_history l√† list ƒë·ªÉ c√≥ th·ªÉ truy c·∫≠p index
        if isinstance(current_chat_history, list) and len(current_chat_history) > response_index:
            current_chat_history[response_index][1] = error_msg
        else: # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p history kh√¥ng h·ª£p l·ªá
            current_chat_history.append([message, error_msg])
        final_history_tuples = [tuple(item) for item in current_chat_history]
        yield "", final_history_tuples, final_history_tuples


# 4) UI Gradio (Gi·ªØ nguy√™n CSS tƒÉng k√≠ch th∆∞·ªõc ch·ªØ)
custom_font_and_size_css = f"""
@import url('https://fonts.googleapis.com/css2?family=Nunito:wght@800&display=swap');

/* √Åp d·ª•ng ph√¥ng v√† k√≠ch th∆∞·ªõc cho bot */
.gradio-container .chatbot .message.bot {{
    font-family: 'Nunito', sans-serif !important;
    font-weight: 800 !important;
    font-size: 1.8em !important; /* Gi·ªØ nguy√™n k√≠ch th∆∞·ªõc ch·ªØ l·ªõn */
    line-height: 1.5 !important;
    word-break: break-word; /* Gi√∫p xu·ªëng d√≤ng t·ªët h∆°n */
}}

/* √Åp d·ª•ng k√≠ch th∆∞·ªõc ch·ªØ cho ng∆∞·ªùi d√πng */
.gradio-container .chatbot .message.user {{
    font-size: 1.8em !important; /* Gi·ªØ nguy√™n k√≠ch th∆∞·ªõc ch·ªØ l·ªõn */
    line-height: 1.5 !important;
    word-break: break-word; /* Gi√∫p xu·ªëng d√≤ng t·ªët h∆°n */
}}
"""

# X√¢y d·ª±ng giao di·ªán v·ªõi Blocks v√† CSS t√πy ch·ªânh
with gr.Blocks(theme=gr.themes.Default(font=[gr.themes.GoogleFont("Nunito"), "Arial", "sans-serif"]), css=custom_font_and_size_css) as demo:
    gr.Markdown("# ‚ú® ZyRa X - T·∫°o b·ªüi D≈©ng ‚ú®")

    # S·ª≠ d·ª•ng state ƒë·ªÉ l∆∞u l·ªãch s·ª≠ d∆∞·ªõi d·∫°ng list c·ªßa tuples [(user1, bot1), (user2, bot2)]
    # ƒê√¢y l√† ƒë·ªãnh d·∫°ng m√† Gradio Chatbot component th∆∞·ªùng mong ƒë·ª£i
    chat_history_state = gr.State(value=[])

    chatbot = gr.Chatbot(
        label="Cu·ªôc tr√≤ chuy·ªán",
        height=600, # TƒÉng chi·ªÅu cao m·ªôt ch√∫t
        bubble_full_width=False,
        # type='tuples', # Kh√¥ng c·∫ßn ch·ªâ ƒë·ªãnh type ·ªü ƒë√¢y n·ªØa n·∫øu d√πng State ƒë√∫ng c√°ch
        value=[], # Kh·ªüi t·∫°o r·ªóng
        render_markdown=True,
        latex_delimiters=[
            { "left": "$$", "right": "$$", "display": True },
            { "left": "$", "right": "$", "display": False },
        ],
        show_label=False # ·∫®n label "Chatbot" n·∫øu mu·ªën
    )


    with gr.Row():
        msg = gr.Textbox(
            placeholder="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n ·ªü ƒë√¢y...",
            label="Tin nh·∫Øn c·ªßa b·∫°n",
            scale=4, # Chi·∫øm nhi·ªÅu kh√¥ng gian h∆°n
            container=False,
            show_label=False # ·∫®n label n·∫øu kh√¥ng c·∫ßn
        )
        send_btn = gr.Button(" G·ª≠i üöÄ", variant="primary", scale=1) # Th√™m icon v√† l√†m n√∫t ch√≠nh

    clear_btn = gr.Button("üóëÔ∏è X√≥a cu·ªôc tr√≤ chuy·ªán")

    # --- K·∫øt n·ªëi s·ª± ki·ªán ---
    # S·ª≠ d·ª•ng h√†m wrapper ƒë·ªÉ ƒë·∫£m b·∫£o state ƒë∆∞·ª£c truy·ªÅn ƒë√∫ng c√°ch
    def wrapped_respond(message, history_list_of_tuples):
        # H√†m respond gi·ªù nh·∫≠n v√† tr·∫£ v·ªÅ list c·ªßa tuples
        # H√†m respond n·ªôi b·ªô s·∫Ω x·ª≠ l√Ω chuy·ªÉn ƒë·ªïi sang list c·ªßa lists khi c·∫ßn
        # chat_history_state s·∫Ω t·ª± ƒë·ªông c·∫≠p nh·∫≠t v√¨ n√≥ l√† ƒë·∫ßu ra
        return respond(message, history_list_of_tuples)

    # K·∫øt n·ªëi msg.submit v√† send_btn.click
    submit_event = msg.submit(
        fn=wrapped_respond,
        inputs=[msg, chat_history_state],
        outputs=[msg, chatbot, chat_history_state], # chatbot nh·∫≠n tr·ª±c ti·∫øp list of tuples t·ª´ state
        api_name="send_message" # ƒê·∫∑t t√™n cho API endpoint (t√πy ch·ªçn)
    )
    click_event = send_btn.click(
        fn=wrapped_respond,
        inputs=[msg, chat_history_state],
        outputs=[msg, chatbot, chat_history_state], # chatbot nh·∫≠n tr·ª±c ti·∫øp list of tuples t·ª´ state
        api_name="send_message_button" # ƒê·∫∑t t√™n kh√°c n·∫øu mu·ªën
    )

    # H√†m x√≥a chat
    def clear_chat_func():
        print("[INFO] ƒê√£ x√≥a l·ªãch s·ª≠ chat.")
        return "", [], [] # msg r·ªóng, chatbot r·ªóng (list), state r·ªóng (list)

    clear_btn.click(
        fn=clear_chat_func,
        inputs=None, # Kh√¥ng c·∫ßn input
        outputs=[msg, chatbot, chat_history_state], # msg, chatbot, v√† state c·∫ßn ƒë∆∞·ª£c x√≥a
        queue=False # Ch·∫°y ngay l·∫≠p t·ª©c, kh√¥ng c·∫ßn x·∫øp h√†ng
    )

# 5) Ch·∫°y ·ª©ng d·ª•ng Gradio (Gi·ªØ nguy√™n)
print("ƒêang kh·ªüi ch·∫°y Gradio UI...")
demo.queue().launch(
    server_name='0.0.0.0',
    server_port=int(os.environ.get('PORT', 7860)),
    debug=False, # T·∫Øt debug trong m√¥i tr∆∞·ªùng production
    # share=True # B·∫≠t n·∫øu b·∫°n mu·ªën t·∫°o link public t·∫°m th·ªùi (Nguy hi·ªÉm n·∫øu API key l·ªô)
)
print("Gradio UI ƒë√£ kh·ªüi ch·∫°y.")
