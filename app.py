# -*- coding: utf-8 -*-
import os
import sys
import gradio as gr
import google.generativeai as genai
from google.api_core import exceptions as google_exceptions

# --- API Key ƒë∆∞·ª£c ƒë·∫∑t tr·ª±c ti·∫øp theo y√™u c·∫ßu ---
# L∆∞u √Ω: Key n√†y ƒë√£ b√°o l·ªói kh√¥ng h·ª£p l·ªá ·ªü l·∫ßn ki·ªÉm tra tr∆∞·ªõc.
# N·∫øu n√≥ v·∫´n kh√¥ng h·ª£p l·ªá, ·ª©ng d·ª•ng s·∫Ω b√°o l·ªói trong chat.
API_KEY = "AIzaSyBybfBSDLx39DdnZbHyLbd21tQAdfHtbeE"

genai_configured = False
# 1) Ki·ªÉm tra v√† c·∫•u h√¨nh API Key t·ª´ code
if not API_KEY:
    print("[ERROR] API Key b·ªã thi·∫øu trong code.]")
else:
    print("[INFO] API Key ƒë∆∞·ª£c t·∫£i tr·ª±c ti·∫øp t·ª´ code.") # B·ªè c·∫£nh b√°o nguy hi·ªÉm kh·ªèi log
    print("ƒêang c·∫•u h√¨nh Google AI...")
    try:
        genai.configure(api_key=API_KEY)
        genai_configured = True
        print("[OK] Google AI ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh th√†nh c√¥ng (c√∫ ph√°p).")
    except Exception as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ c·∫•u h√¨nh Google AI ngay c·∫£ v·ªõi c√∫ ph√°p: {e}")
        genai_configured = False

# 2) Model v√† H√†m tr·ª£ gi√∫p ƒë·ªãnh d·∫°ng l·ªói
# --- S·ª¨ D·ª§NG MODEL B·∫†N Y√äU C·∫¶U ---
MODEL_NAME_CHAT = "gemini-2.5-pro-exp-03-25"
print(f"S·ª≠ d·ª•ng model chat: {MODEL_NAME_CHAT}")

def format_api_error(e):
    # ... (H√†m format_api_error gi·ªØ nguy√™n nh∆∞ phi√™n b·∫£n tr∆∞·ªõc) ...
    error_message = str(e)
    error_type = type(e).__name__
    print(f"[ERROR] L·ªói khi g·ªçi API: {error_type} - {error_message}") # Log l·ªói

    if isinstance(e, google_exceptions.PermissionDenied):
        if "API key not valid" in error_message or "API_KEY_INVALID" in error_message:
             return "‚ùå L·ªói: API Key ƒë∆∞·ª£c c·∫•u h√¨nh nh∆∞ng Google t·ª´ ch·ªëi khi s·ª≠ d·ª•ng (API_KEY_INVALID). C√≥ th·ªÉ key ƒë√£ b·ªã v√¥ hi·ªáu h√≥a."
        else: # L·ªói quy·ªÅn truy c·∫≠p model
             # C·∫≠p nh·∫≠t th√¥ng b√°o l·ªói ƒë·ªÉ ph·∫£n √°nh ƒë√∫ng model ƒëang d√πng
             return f"‚ùå L·ªói: T·ª´ ch·ªëi quy·ªÅn truy c·∫≠p (Permission Denied) cho model '{MODEL_NAME_CHAT}'. API key c·ªßa b·∫°n c√≥ th·ªÉ kh√¥ng c√≥ quy·ªÅn s·ª≠ d·ª•ng model n√†y ho·∫∑c ch∆∞a b·∫≠t 'Generative Language API' trong Google Cloud."
    elif isinstance(e, google_exceptions.InvalidArgument) and "API key not valid" in error_message:
        # L·ªói key kh√¥ng h·ª£p l·ªá nh∆∞ log tr∆∞·ªõc ƒë√≥
        return "‚ùå L·ªói: API Key kh√¥ng h·ª£p l·ªá (InvalidArgument). Key cung c·∫•p kh√¥ng ƒë√∫ng ho·∫∑c ƒë√£ b·ªã v√¥ hi·ªáu h√≥a."
    elif isinstance(e, google_exceptions.NotFound):
         return f"‚ùå L·ªói: Model '{MODEL_NAME_CHAT}' kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng t·ªìn t·∫°i v·ªõi API key c·ªßa b·∫°n."
    elif isinstance(e, google_exceptions.ResourceExhausted):
         return "‚ùå L·ªói: ƒê√£ v∆∞·ª£t qu√° H·∫°n ng·∫°ch API (Quota) ho·∫∑c T√†i nguy√™n ƒë√£ c·∫°n ki·ªát (429). Vui l√≤ng th·ª≠ l·∫°i sau."
    elif isinstance(e, google_exceptions.DeadlineExceeded):
         return "‚ùå L·ªói: Y√™u c·∫ßu v∆∞·ª£t qu√° th·ªùi gian ch·ªù (Timeout/Deadline Exceeded/504)."
    elif isinstance(e, AttributeError) and "start_chat" in error_message:
         return f"‚ùå L·ªói: Model '{MODEL_NAME_CHAT}' c√≥ th·ªÉ kh√¥ng h·ªó tr·ª£ ph∆∞∆°ng th·ª©c `start_chat`."
    else: # C√°c l·ªói kh√°c
         return f"‚ùå L·ªói khi g·ªçi AI ({error_type}): {error_message}"


# 3) H√†m callback Gradio (C√≥ ghi nh·ªõ & Streaming, ƒë√£ s·ª≠a yield)
def respond(message, chat_history_state):
    if not genai_configured:
        error_msg = "‚ùå L·ªói: Google AI ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng c√°ch (API Key c√≥ v·∫•n ƒë·ªÅ ho·∫∑c c·∫•u h√¨nh th·∫•t b·∫°i)."
        if isinstance(chat_history_state, list):
             chat_history_state.append([message, error_msg])
        else:
             chat_history_state = [[message, error_msg]]
        return "", chat_history_state, chat_history_state

    current_chat_history = list(chat_history_state)
    gemini_history = []
    for user_msg, model_msg in current_chat_history:
        if user_msg and isinstance(user_msg, str):
             gemini_history.append({'role': 'user', 'parts': [user_msg]})
        if model_msg and isinstance(model_msg, str) and not model_msg.startswith("‚ùå") and not model_msg.startswith("‚ö†Ô∏è"):
             gemini_history.append({'role': 'model', 'parts': [model_msg]})

    print(f"L·ªãch s·ª≠ g·ª≠i t·ªõi Gemini: {gemini_history}")
    print(f"Prompt m·ªõi: '{message[:70]}...'")

    try:
        model = genai.GenerativeModel(MODEL_NAME_CHAT) # S·ª≠ d·ª•ng model ƒë√£ ch·ªçn
        chat = model.start_chat(history=gemini_history)
        response = chat.send_message(message, stream=True)

        current_chat_history.append([message, ""])
        full_response_text = ""

        for chunk in response:
            try:
                chunk_text = getattr(chunk, 'text', '')
                if chunk_text:
                    full_response_text += chunk_text
                    current_chat_history[-1][1] = full_response_text
                    yield "", current_chat_history, current_chat_history
                else:
                    # (Logic ki·ªÉm tra block/finish reason gi·ªØ nguy√™n)
                    block_reason = getattr(getattr(chunk, 'prompt_feedback', None), 'block_reason', None)
                    finish_reason = getattr(getattr(chunk.candidates[0], 'finish_reason', None)) if chunk.candidates else None
                    reason_text = ""
                    should_stop = False
                    if block_reason: reason_text, should_stop = f"Y√™u c·∫ßu/Ph·∫£n h·ªìi b·ªã ch·∫∑n ({block_reason})", True
                    elif finish_reason and finish_reason != 'STOP': reason_text, should_stop = f"Ph·∫£n h·ªìi b·ªã d·ª´ng ({finish_reason})", True

                    if reason_text:
                        print(f"[WARN] {reason_text}")
                        warning_msg = f"\n‚ö†Ô∏è ({reason_text})"
                        if not current_chat_history[-1][1] or current_chat_history[-1][1].isspace(): current_chat_history[-1][1] = warning_msg.strip()
                        elif warning_msg not in current_chat_history[-1][1]: current_chat_history[-1][1] += warning_msg
                        yield "", current_chat_history, current_chat_history
                        if should_stop: return

            except Exception as inner_e:
                print(f"[ERROR] L·ªói khi x·ª≠ l√Ω chunk stream: {type(inner_e).__name__} - {inner_e}")
                error_warning = f"\n‚ö†Ô∏è (L·ªói khi x·ª≠ l√Ω ph·∫ßn ti·∫øp theo: {inner_e})"
                if error_warning not in current_chat_history[-1][1]:
                    current_chat_history[-1][1] += error_warning
                yield "", current_chat_history, current_chat_history
                return

        print("[OK] Streaming ho√†n t·∫•t.")

    except Exception as e:
        error_msg = format_api_error(e)
        current_chat_history.append([message, error_msg])
        yield "", current_chat_history, current_chat_history


# 4) UI Gradio (S·ª≠ d·ª•ng State ƒë·ªÉ l∆∞u l·ªãch s·ª≠)
with gr.Blocks(theme=gr.themes.Default()) as demo:
    gr.Markdown("## ZyRa X - t·∫°o b·ªüi D≈©ng")
    # --- ƒê√É X√ìA D√íNG C·∫¢NH B√ÅO B·∫¢O M·∫¨T KH·ªéI UI ---
    # gr.Markdown("üö® **C·∫£nh b√°o:** ... ", elem_classes="warning") # <-- ƒê√£ x√≥a d√≤ng n√†y

    chatbot = gr.Chatbot(
        label="Chatbot",
        height=500,
        bubble_full_width=False,
        type='tuples', # Ch·ªâ ƒë·ªãnh r√µ r√†ng
        # avatar_images=("user.png", "bot.png")
        render_markdown=True, # ƒê·∫£m b·∫£o markdown rendering ƒë∆∞·ª£c b·∫≠t (m·∫∑c ƒë·ªãnh l√† True)
        latex_delimiters=[
            { "left": "$$", "right": "$$", "display": True },
            { "left": "$", "right": "$", "display": False },
            # B·∫°n c≈©ng c√≥ th·ªÉ th√™m \[\], \( \) n·∫øu AI tr·∫£ v·ªÅ:
            # { "left": "\\[", "right": "\\]", "display": True },
            # { "left": "\\(", "right": "\\)", "display": False }
        ]
    )
    chat_history_state = gr.State(value=[])

    with gr.Row():
        msg = gr.Textbox(placeholder="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n...", label="B·∫°n", scale=4, container=False)
        send_btn = gr.Button("G·ª≠i")

    clear_btn = gr.Button("üóëÔ∏è X√≥a cu·ªôc tr√≤ chuy·ªán")

    # --- K·∫øt n·ªëi s·ª± ki·ªán ---
    submit_event = msg.submit(respond, inputs=[msg, chat_history_state], outputs=[msg, chatbot, chat_history_state])
    click_event = send_btn.click(respond, inputs=[msg, chat_history_state], outputs=[msg, chatbot, chat_history_state])

    # H√†m x√≥a chat
    def clear_chat_func(): return "", [], []
    clear_btn.click(clear_chat_func, outputs=[msg, chatbot, chat_history_state], queue=False)

# 5) Ch·∫°y ·ª©ng d·ª•ng
print("ƒêang kh·ªüi ch·∫°y Gradio UI...")
# Modified launch command to bind to 0.0.0.0 and use the PORT environment variable
demo.queue().launch(server_name='0.0.0.0', server_port=int(os.environ.get('PORT', 7860)), debug=False)
print("Gradio UI ƒë√£ kh·ªüi ch·∫°y.")
